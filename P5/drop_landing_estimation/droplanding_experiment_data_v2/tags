!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
ACC_GYRO_FIELDS	package_lib/const.py	/^ACC_GYRO_FIELDS = ['Accel_X', 'Accel_Y', 'Accel_Z', 'Gyro_X', 'Gyro_Y', 'Gyro_Z']$/;"	v
ALL_FIELDS	package_lib/const.py	/^ALL_FIELDS = DISCRETE_FIELDS + CONTINUOUS_FIELDS$/;"	v
BASIC_COP_DATA_FIELDS	package_lib/const.py	/^BASIC_COP_DATA_FIELDS=['COP']$/;"	v
BASIC_KNEE_DATA_FIELDS	package_lib/const.py	/^BASIC_KNEE_DATA_FIELDS=['KneeAngle_X','KneeAngle_Y','KneeMoment_X','KneeMoment_Y']$/;"	v
CONTINUOUS_FIELDS	package_lib/const.py	/^                    JOINT_LIST + SEGMENT_DATA_FIELDS$/;"	v
DATA_PATH	package_lib/const.py	/^DATA_PATH="\/media\/sun\/My Passport\/DropLanding_workspace\/suntao\/D drop landing"$/;"	v
DATA_VISULIZATION_PATH	package_lib/const.py	/^DATA_VISULIZATION_PATH=os.path.join(EXPERIMENT_RESULTS_PATH,'datasets_files','dataset_visulization')$/;"	v
DIRECTIONS	package_lib/const.py	/^DIRECTIONS=['_X','_Y','_Z']$/;"	v
DISCRETE_FIELDS	package_lib/const.py	/^DISCRETE_FIELDS = STATIC_DATA + PHASE_LIST$/;"	v
DNN_A_Graph	rnn_model.py	/^    def DNN_A_Graph(x,n_input=36,n_output=6,name='Transfer_graph'):$/;"	f	function:model_v2
DNN_B_Graph	rnn_model.py	/^    def DNN_B_Graph(x,n_input=36,n_output=6,name='Main_graph'):$/;"	f	function:model_v2
DROPLANDING_PERIOD	package_lib/const.py	/^DROPLANDING_PERIOD=60 # 落地后的两秒内， 这是研究每次落地实验的时间范围$/;"	v
DYNAMIC_TRIALS	package_lib/const.py	/^DYNAMIC_TRIALS = ['baseline', 'fpa_01', 'fpa_02','fpa_03','fpa_04','fpa_05','single']$/;"	v
DYNAMIC_TRIALS	package_lib/const.py	/^DYNAMIC_TRIALS = ['baseline', 'parallel', 'toe_in', 'toe_out']$/;"	v
DivideMaxScalar	package_lib/wearable_toolkit.py	/^class DivideMaxScalar(MinMaxScaler):$/;"	c
DroplandingDataset	fnn_model.py	/^class DroplandingDataset(torch.utils.data.Dataset):$/;"	c
DroplandingDataset	package_lib/fnn_model_bk.py	/^class DroplandingDataset(torch.utils.data.Dataset):$/;"	c
EXAMPLE_DATA_FIELDS	package_lib/const.py	/^EXAMPLE_DATA_FIELDS = [$/;"	v
EXPERIMENT_RESULTS_PATH	package_lib/const.py	/^EXPERIMENT_RESULTS_PATH="\/media\/sun\/My Passport\/DropLanding_workspace\/suntao\/Results\/Experimental_Results"$/;"	v
EXPERIMENT_RESULTS_PATH	package_lib/const.py	/^EXPERIMENT_RESULTS_PATH="\/media\/sun\/My Passport\/Experimental_Results"$/;"	v
EXT_KNEE_MOMENT	package_lib/const.py	/^EXT_KNEE_MOMENT = ['EXT_KM_X', 'EXT_KM_Y', 'EXT_KM_Z']$/;"	v
FEATURES_FIELDS	package_lib/const.py	/^FEATURES_FIELDS = extract_imu_fields(IMU_SENSOR_LIST, IMU_RAW_FIELDS)$/;"	v
FONT_DICT	package_lib/const.py	/^FONT_DICT = {'fontsize': FONT_SIZE, 'fontname': 'Arial'}$/;"	v
FONT_DICT_LARGE	package_lib/const.py	/^FONT_DICT_LARGE = {'fontsize': FONT_SIZE_LARGE, 'fontname': 'Arial'}$/;"	v
FONT_DICT_SMALL	package_lib/const.py	/^FONT_DICT_SMALL = {'fontsize': FONT_SIZE_SMALL, 'fontname': 'Arial'}$/;"	v
FONT_DICT_X_SMALL	package_lib/const.py	/^FONT_DICT_X_SMALL = {'fontsize': 15, 'fontname': 'Arial'}$/;"	v
FONT_SIZE	package_lib/const.py	/^FONT_SIZE = 20$/;"	v
FONT_SIZE_LARGE	package_lib/const.py	/^FONT_SIZE_LARGE = 24$/;"	v
FONT_SIZE_SMALL	package_lib/const.py	/^FONT_SIZE_SMALL = 18$/;"	v
FORCE	package_lib/const.py	/^FORCE=['Force']$/;"	v
FORCE_DATA_FIELDS	package_lib/const.py	/^FORCE_DATA_FIELDS = ['plate_' + num + '_' + data_type + '_' + axis for num in ['1', '2']$/;"	v
FORCE_DATA_FIELDS	package_lib/const.py	/^FORCE_DATA_FIELDS=  [lr + 'Force' + dire for lr in LEFT_RIGHT for dire in DIRECTIONS]$/;"	v
FORCE_PLATE_DATA_FIELDS	package_lib/const.py	/^FORCE_PLATE_DATA_FIELDS = ['plate_' + num + '_' + data_type + '_' + axis for num in ['1', '2']$/;"	v
GRAVITY	package_lib/const.py	/^GRAVITY = 9.81$/;"	v
GUESSED_EVENT_INDEX	package_lib/wearable_toolkit.py	/^    GUESSED_EVENT_INDEX = 0$/;"	v	class:SageCsvReader
IMU_DATA_FIELDS	package_lib/const.py	/^IMU_DATA_FIELDS = extract_imu_fields(IMU_SENSOR_LIST, IMU_FIELDS)$/;"	v
IMU_FEATURES_FIELDS	package_lib/const.py	/^IMU_FEATURES_FIELDS = extract_imu_fields(IMU_SENSOR_LIST, IMU_RAW_FIELDS)$/;"	v
IMU_FIELDS	package_lib/const.py	/^IMU_FIELDS = ['Accel_X', 'Accel_Y', 'Accel_Z', 'Gyro_X', 'Gyro_Y', 'Gyro_Z', 'Mag_X', 'Mag_Y', 'Mag_Z', 'Quat_1', 'Quat_2',$/;"	v
IMU_RAW_FIELDS	package_lib/const.py	/^IMU_RAW_FIELDS = ['Accel_X', 'Accel_Y', 'Accel_Z', 'Gyro_X', 'Gyro_Y', 'Gyro_Z', 'Mag_X', 'Mag_Y', 'Mag_Z',]$/;"	v
IMU_SENSOR_LIST	package_lib/const.py	/^IMU_SENSOR_LIST = ['CHEST','WAIST', 'R_THIGH', 'R_SHANK','R_FOOT','L_THIGH','L_SHANK','L_FOOT']$/;"	v
JOINT_LIST	package_lib/const.py	/^JOINT_LIST = [marker + '_' + axis for axis in ['X', 'Y', 'Z'] for marker in sum(SEGMENT_DEFINITIONS.values(), [])]$/;"	v
KNEE_DATA_FIELDS	package_lib/const.py	/^KNEE_DATA_FIELDS = [lr + knee + dire for lr in LEFT_RIGHT for knee in KNEE_VALUES for dire in DIRECTIONS[:2]]$/;"	v
KNEE_VALUES	package_lib/const.py	/^KNEE_VALUES=['KneeAngle','KneeMoment']$/;"	v
LABELS_FIELDS	package_lib/const.py	/^LABELS_FIELDS= ['L_KneeMoment_X','R_KneeMoment_X']$/;"	v
LEFT_RIGHT	package_lib/const.py	/^LEFT_RIGHT=['L_','R_']$/;"	v
LEVER_ARM_FIELDS	package_lib/const.py	/^LEVER_ARM_FIELDS = ['r_x', 'r_y', 'r_z']$/;"	v
LINE_WIDTH	package_lib/const.py	/^LINE_WIDTH = 2$/;"	v
LINE_WIDTH_THICK	package_lib/const.py	/^LINE_WIDTH_THICK = 3$/;"	v
MyFNN_ModelV2	fnn_model.py	/^class MyFNN_ModelV2(nn.Module):$/;"	c
MyFNN_ModelV2	package_lib/fnn_model_bk.py	/^class MyFNN_ModelV2(nn.Module):$/;"	c
MyLSTM_MoldeV1	fnn_model.py	/^class MyLSTM_MoldeV1(nn.Module):$/;"	c
MyLSTM_MoldeV1	package_lib/fnn_model_bk.py	/^class MyLSTM_MoldeV1(nn.Module):$/;"	c
MyLSTM_MoldeV2	fnn_model.py	/^class MyLSTM_MoldeV2(nn.Module):$/;"	c
MyLSTM_MoldeV2	package_lib/fnn_model_bk.py	/^class MyLSTM_MoldeV2(nn.Module):$/;"	c
OPENPOSE_MODEL_PATH	package_lib/const.py	/^OPENPOSE_MODEL_PATH = os.environ.get('OPENPOSE_MODEL_PATH')$/;"	v
RKNEE_MARKER_FIELDS	package_lib/const.py	/^RKNEE_MARKER_FIELDS = [marker + axis for marker in ['RFME', 'RFLE'] for axis in ['_X', '_Y', '_Z']]$/;"	v
SAMPLES_AFTER_STEP	package_lib/const.py	/^SAMPLES_AFTER_STEP = 20$/;"	v
SAMPLES_BEFORE_STEP	package_lib/const.py	/^SAMPLES_BEFORE_STEP = 20$/;"	v
SEGMENT_DATA_FIELDS	package_lib/const.py	/^SEGMENT_DATA_FIELDS = [seg_name + '_' + axis for axis in ['X', 'Y', 'Z'] for seg_name in SEGMENT_DEFINITIONS.keys()]$/;"	v
SEGMENT_DEFINITIONS	package_lib/const.py	/^SEGMENT_DEFINITIONS = {$/;"	v
SEGMENT_MASS_PERCENT	package_lib/const.py	/^SEGMENT_MASS_PERCENT = {'L_FOOT': 1.37, 'R_FOOT': 1.37, 'R_SHANK': 4.33, 'R_THIGH': 14.16,$/;"	v
SENSOR_COMBINATION	package_lib/const.py	/^SENSOR_COMBINATION = ['8IMU_2camera', '8IMU', '3IMU_2camera', '3IMU', '1IMU_2camera', '1IMU', '2camera']$/;"	v
SENSOR_COMBINATION_SORTED	package_lib/const.py	/^SENSOR_COMBINATION_SORTED = ['8IMU_2camera', '3IMU_2camera', '8IMU', '1IMU_2camera', '3IMU', '2camera', '1IMU']$/;"	v
SESSIONS	package_lib/const.py	/^SESSIONS=['20210926_vicon','20211015_vicon','20211022_vicon','20211025_vicon','20211026_vicon']$/;"	v
STATIC_TRIALS	package_lib/const.py	/^STATIC_TRIALS = ['static']$/;"	v
STEP_TYPE	package_lib/const.py	/^STEP_TYPE = STANCE$/;"	v
SUBJECTS	package_lib/const.py	/^SUBJECTS = [#'P_01_suntao',$/;"	v
SageCsvReader	package_lib/wearable_toolkit.py	/^class SageCsvReader:$/;"	c
TRIALS	package_lib/const.py	/^TRIALS = [str(idx) if idx>9 else '0'+str(idx) for idx in range(1,TRIAL_NUM+1,1)]$/;"	v
TRIAL_NUM	package_lib/const.py	/^TRIAL_NUM=40$/;"	v
TRUE_EVENT_INDEX	package_lib/wearable_toolkit.py	/^    TRUE_EVENT_INDEX = 0$/;"	v	class:Visual3dCsvReader
V3DReader	package_lib/dp_load_rawdata.py	/^class V3DReader():$/;"	c
V3D_DATA_FIELDS	package_lib/const.py	/^V3D_DATA_FIELDS=['LON','RON','RIGHT_KNEE_ANGLE', 'RIGHT_KNEE_ANGLE.1',  'RIGHT_KNEE_MOMENT', 'RIGHT_KNEE_MOMENT.1', 'FP1', 'FP1.1','FP1.2','LEFT_KNEE_ANGLE', 'LEFT_KNEE_ANGLE.1',  'LEFT_KNEE_MOMENT', 'LEFT_KNEE_MOMENT.1', 'FP2','FP2.1','FP2.2']$/;"	v
V3D_DATA_FIELDS	package_lib/const.py	/^V3D_DATA_FIELDS=['LON','RON','RIGHT_KNEE_ANGLE', 'RIGHT_KNEE_ANGLE.1',  'RIGHT_KNEE_MOMENT', 'RIGHT_KNEE_MOMENT.1', 'RIGHT_GRF', 'RIGHT_GRF.1','RIGHT_GRF.2','LEFT_KNEE_ANGLE', 'LEFT_KNEE_ANGLE.1',  'LEFT_KNEE_MOMENT', 'LEFT_KNEE_MOMENT.1', 'LEFT_GRF','LEFT_GRF.1','LEFT_GRF.2']$/;"	v
V3D_LABELS_FIELDS	package_lib/const.py	/^V3D_LABELS_FIELDS=['LON','RON']+['R_'+knee + dire for knee in KNEE_VALUES for dire in DIRECTIONS[:2]]+['R_Force'+dire for dire in DIRECTIONS] + ['L_'+knee + dire for knee in KNEE_VALUES for dire in DIRECTIONS[:2]]+['L_Force'+dire for dire in DIRECTIONS] $/;"	v
VIDEO_ANGLES	package_lib/const.py	/^VIDEO_ANGLES = ["90", "180"]$/;"	v
VIDEO_DATA_FIELDS	package_lib/const.py	/^VIDEO_DATA_FIELDS = extract_video_fields(VIDEO_LIST, VIDEO_ANGLES)$/;"	v
VIDEO_LIST	package_lib/const.py	/^VIDEO_LIST = ["LShoulder", "RShoulder", "MidHip", "RHip", "LHip", "RKnee", "LKnee", "RAnkle", "LAnkle", "RHeel",$/;"	v
VIDEO_ORIGINAL_SAMPLE_RATE	package_lib/const.py	/^VIDEO_ORIGINAL_SAMPLE_RATE = 119.99014859206962$/;"	v
VIDEO_PATH	package_lib/const.py	/^VIDEO_PATH = os.environ.get('VIDEO_DATA_PATH')$/;"	v
ViconCsvReader	package_lib/wearable_toolkit.py	/^class ViconCsvReader:$/;"	c
ViconReader	package_lib/dp_load_rawdata.py	/^class ViconReader():$/;"	c
VideoCsvReader	package_lib/wearable_toolkit.py	/^class VideoCsvReader:$/;"	c
Visual3dCsvReader	package_lib/wearable_toolkit.py	/^class Visual3dCsvReader:$/;"	c
XSEN_IMU_ID	package_lib/const.py	/^XSEN_IMU_ID={'MASTER':'0120092C','CHEST':'00B44914','WAIST':'00B44918','L_THIGH':'00B44915','L_SHANK':'00B44909','L_FOOT':'00B44907','R_THIGH':'00B4490C','R_SHANK':'00B4490E','R_FOOT':'00B44911'}$/;"	v
XsenReader	package_lib/dp_load_rawdata.py	/^class XsenReader():$/;"	c
XsenTxtReader	package_lib/wearable_toolkit.py	/^class XsenTxtReader():$/;"	c
__find_stationary_phase	package_lib/wearable_toolkit.py	/^    def __find_stationary_phase(gyr_magnitude, acc_magnitude, foot_stationary_acc_thd, foot_stationary_gyr_thd):$/;"	m	class:SageCsvReader	file:
__find_stationary_phase_2	package_lib/wearable_toolkit.py	/^    def __find_stationary_phase_2(gyr_magnitude, acc_magnitude, foot_stationary_acc_thd, foot_stationary_gyr_thd):$/;"	m	class:SageCsvReader	file:
__find_zero_crossing	package_lib/wearable_toolkit.py	/^    def __find_zero_crossing(self, gyr_x, foot_stationary_gyr_thd, i_sample):$/;"	m	class:SageCsvReader	file:
__getitem__	fnn_model.py	/^    def __getitem__(self,row_idx):       $/;"	m	class:DroplandingDataset	file:
__getitem__	package_lib/fnn_model_bk.py	/^    def __getitem__(self,row_idx):       $/;"	m	class:DroplandingDataset	file:
__init__	fnn_model.py	/^    def __init__(self, input_size, hidden_size, num_layers, output_size,seed=0,device='cpu'):$/;"	m	class:MyLSTM_MoldeV1
__init__	fnn_model.py	/^    def __init__(self, input_size, hidden_size, num_layers, output_size,seed=0,device='cpu'):$/;"	m	class:MyLSTM_MoldeV2
__init__	fnn_model.py	/^    def __init__(self, num_features, num_labels):$/;"	m	class:MyFNN_ModelV2
__init__	fnn_model.py	/^    def __init__(self,datafile,features_names,labels_names,train=True,norm_type='mean_std',preprocess_filer=False):$/;"	m	class:DroplandingDataset
__init__	package_lib/dp_load_rawdata.py	/^    def __init__(self,subject_info,session):$/;"	m	class:V3DReader
__init__	package_lib/dp_load_rawdata.py	/^    def __init__(self,subject_info,session):$/;"	m	class:ViconReader
__init__	package_lib/dp_load_rawdata.py	/^    def __init__(self,subject_info,session):$/;"	m	class:XsenReader
__init__	package_lib/fnn_model_bk.py	/^    def __init__(self, input_size, hidden_size, num_layers, output_size,seed=0,device='cpu'):$/;"	m	class:MyLSTM_MoldeV1
__init__	package_lib/fnn_model_bk.py	/^    def __init__(self, input_size, hidden_size, num_layers, output_size,seed=0,device='cpu'):$/;"	m	class:MyLSTM_MoldeV2
__init__	package_lib/fnn_model_bk.py	/^    def __init__(self, num_features, num_labels):$/;"	m	class:MyFNN_ModelV2
__init__	package_lib/fnn_model_bk.py	/^    def __init__(self,datafile,features_names,labels_names,train=True,norm_type='mean_std',preprocess_filer=False):$/;"	m	class:DroplandingDataset
__init__	package_lib/wearable_toolkit.py	/^    def __init__(self, file_path):$/;"	m	class:SageCsvReader
__init__	package_lib/wearable_toolkit.py	/^    def __init__(self, file_path):$/;"	m	class:VideoCsvReader
__init__	package_lib/wearable_toolkit.py	/^    def __init__(self, file_path):$/;"	m	class:Visual3dCsvReader
__init__	package_lib/wearable_toolkit.py	/^    def __init__(self, file_path,trial=None, segment_definitions=None, static_trial=None, subject_info=None):$/;"	m	class:ViconCsvReader
__init__	package_lib/wearable_toolkit.py	/^    def __init__(self,folder_path,trial):$/;"	m	class:XsenTxtReader
__len__	fnn_model.py	/^    def __len__(self):$/;"	m	class:DroplandingDataset	file:
__len__	package_lib/fnn_model_bk.py	/^    def __len__(self):$/;"	m	class:DroplandingDataset	file:
all_datasets_len	fnn_model.py	/^all_datasets_len={'sub_0':6951, 'sub_1':7439, 'sub_2': 7686, 'sub_3': 8678, 'sub_4':6180, 'sub_5': 6671,$/;"	v
all_datasets_len	package_lib/dp_process_rawdata.py	/^all_datasets_len={'sub_0':6951, 'sub_1':7439, 'sub_2': 7686, 'sub_3': 8678, 'sub_4':6180, 'sub_5': 6671,$/;"	v
all_datasets_len	package_lib/fnn_model_bk.py	/^all_datasets_len={'sub_0':6951, 'sub_1':7439, 'sub_2': 7686, 'sub_3': 8678, 'sub_4':6180, 'sub_5': 6671,$/;"	v
all_datasets_ranges	fnn_model.py	/^all_datasets_ranges={'sub_-1':0,'sub_0': 6951, 'sub_1': 14390, 'sub_2': 22076, 'sub_3': 30754, 'sub_4': 36934, 'sub_5': 43605,$/;"	v
all_datasets_ranges	package_lib/dp_process_rawdata.py	/^all_datasets_ranges={'sub_-1':0,'sub_0': 6951, 'sub_1': 14390, 'sub_2': 22076, 'sub_3': 30754, 'sub_4': 36934, 'sub_5': 43605,$/;"	v
all_datasets_ranges	package_lib/fnn_model_bk.py	/^all_datasets_ranges={'sub_-1':0,'sub_0': 6951, 'sub_1': 14390, 'sub_2': 22076, 'sub_3': 30754, 'sub_4': 36934, 'sub_5': 43605,$/;"	v
append_external_kam	package_lib/wearable_toolkit.py	/^    def append_external_kam(self):$/;"	m	class:ViconCsvReader
batch_size	fnn_model.py	/^    batch_size=hyperparams['batch_size']$/;"	v
batch_size	package_lib/fnn_model_bk.py	/^    batch_size=hyperparams['batch_size']$/;"	v
calibrate_force_plate_center	package_lib/wearable_toolkit.py	/^def calibrate_force_plate_center(file_path, plate_num):$/;"	f
col_names	fnn_model.py	/^        col_names=['Time_vicon','L_Up_Acc_X', 'L_Up_Acc_Y', 'L_Up_Acc_Z', 'L_Up_Gyr_X', 'L_Up_Gyr_Y','L_Up_Gyr_Z', 'L_Up_Mag_X', 'L_Up_Mag_Y','L_Up_Mag_Z',$/;"	v
col_names	package_lib/fnn_model_bk.py	/^        col_names=['Time_vicon','L_Up_Acc_X', 'L_Up_Acc_Y', 'L_Up_Acc_Z', 'L_Up_Gyr_X', 'L_Up_Gyr_Y','L_Up_Gyr_Z', 'L_Up_Mag_X', 'L_Up_Mag_Y','L_Up_Mag_Z',$/;"	v
columns_names	package_lib/dp_process_rawdata.py	/^columns_names=FEATURES_FIELDS+LABELS_FIELDS$/;"	v
columns_names	package_lib/dp_process_rawdata.py	/^columns_names=features_names+labels_names$/;"	v
cpus	rnn_model.py	/^cpus=tf.config.list_logical_devices(device_type='CPU')$/;"	v
create_step_id	package_lib/wearable_toolkit.py	/^    def create_step_id(self, segment, verbose=False):$/;"	m	class:SageCsvReader
create_step_id	package_lib/wearable_toolkit.py	/^    def create_step_id(self, step_type):$/;"	m	class:Visual3dCsvReader
create_testing_files	package_lib/dp_process_rawdata.py	/^def create_testing_files(training_folder, base_folder=os.path.join(EXPERIMENT_RESULTS_PATH,'models_parameters_results\/')):$/;"	f
create_testing_files	package_lib/fnn_model_bk.py	/^def create_testing_files(training_folder, base_folder='.\/models_parameters_results\/'):$/;"	f
create_training_files	package_lib/dp_process_rawdata.py	/^def create_training_files(model_object=None, hyperparams={'lr':0},base_folder=os.path.join(EXPERIMENT_RESULTS_PATH,'models_parameters_results\/')):$/;"	f
create_training_files	package_lib/fnn_model_bk.py	/^def create_training_files(model_object=None, hyperparams={'lr':0},base_folder='.\/models_parameters_results\/'):$/;"	f
crop	package_lib/wearable_toolkit.py	/^    def crop(self, start_index):$/;"	m	class:SageCsvReader
crop	package_lib/wearable_toolkit.py	/^    def crop(self, start_index):$/;"	m	class:ViconCsvReader
crop	package_lib/wearable_toolkit.py	/^    def crop(self, start_index):$/;"	m	class:VideoCsvReader
crop	package_lib/wearable_toolkit.py	/^    def crop(self, start_index, end_index):$/;"	m	class:XsenTxtReader
crop	package_lib/wearable_toolkit.py	/^    def crop(self, start_index=0, end_index=None):$/;"	m	class:Visual3dCsvReader
data_filter	package_lib/wearable_toolkit.py	/^def data_filter(data, cut_off_fre, sampling_fre, filter_order=4):$/;"	f
datasets	fnn_model.py	/^        datasets=DroplandingDataset(raw_datasets_path,features_names,labels_names,norm_type=norm_type)$/;"	v
datasets	package_lib/fnn_model_bk.py	/^        datasets=DroplandingDataset(raw_datasets_path,features_names,labels_names,norm_type=norm_type)$/;"	v
datasets_ranges	fnn_model.py	/^        datasets_ranges=(0,6951)$/;"	v
datasets_ranges	fnn_model.py	/^        datasets_ranges=(all_datasets_ranges['sub_'+str(sub_idx-1)],all_datasets_ranges['sub_'+str(sub_idx)])$/;"	v
datasets_ranges	package_lib/dp_process_rawdata.py	/^    datasets_ranges=(dp_lib.all_datasets_ranges['sub_'+str(sub_idx-1)],dp_lib.all_datasets_ranges['sub_'+str(sub_idx)])$/;"	v
datasets_ranges	package_lib/fnn_model_bk.py	/^        datasets_ranges=(0,6951)$/;"	v
datasets_ranges	package_lib/fnn_model_bk.py	/^        datasets_ranges=(all_datasets_ranges['sub_'+str(sub_idx-1)],all_datasets_ranges['sub_'+str(sub_idx)])$/;"	v
device	fnn_model.py	/^    device=hyperparams['device']$/;"	v
device	package_lib/fnn_model_bk.py	/^    device=hyperparams['device']$/;"	v
display_rawdatase	package_lib/dp_process_rawdata.py	/^def display_rawdatase(datasets_ranges,col_names,norm_type='mean_std',**args):$/;"	f
display_rawdatase	package_lib/fnn_model_bk.py	/^def display_rawdatase(datasets_ranges,col_names,norm_type='mean_std',**args):$/;"	f
display_rows	package_lib/dp_process_rawdata.py	/^    display_rows=['KneeMoment_X']$/;"	v
drop_landing_period	package_lib/fnn_model_bk.py	/^def drop_landing_period():$/;"	f
drop_landing_range	package_lib/dp_process_rawdata.py	/^def drop_landing_range():$/;"	f
eval_loader	fnn_model.py	/^        eval_loader = torch.utils.data.DataLoader(dataset=eval_sets, batch_size=batch_size, shuffle=True)$/;"	v
eval_loader	package_lib/fnn_model_bk.py	/^        eval_loader = torch.utils.data.DataLoader(dataset=eval_sets, batch_size=batch_size, shuffle=True)$/;"	v
eval_sets	fnn_model.py	/^        eval_sets=torch.utils.data.Subset(datasets,indices_eval)$/;"	v
eval_sets	package_lib/fnn_model_bk.py	/^        eval_sets=torch.utils.data.Subset(datasets,indices_eval)$/;"	v
expr	ptags.py	/^expr = r'^[ \\t]*(def|class)[ \\t]+([a-zA-Z0-9_]+)[ \\t]*[:\\(]'$/;"	v
extract_droplanding_period	package_lib/wearable_toolkit.py	/^    def extract_droplanding_period(self):$/;"	m	class:Visual3dCsvReader
extract_droplanding_period	package_lib/wearable_toolkit.py	/^    def extract_droplanding_period(self):$/;"	m	class:XsenTxtReader
extract_imu_fields	package_lib/const.py	/^extract_imu_fields = lambda imus, fields: [imu + "_" + field for imu in imus for field in fields]$/;"	v
extract_subject_drop_landing_data	package_lib/dp_process_rawdata.py	/^def extract_subject_drop_landing_data(sub_idx: int)->np.ndarray:$/;"	f
extract_subject_drop_landing_data	package_lib/fnn_model_bk.py	/^def extract_subject_drop_landing_data(sub_idx: int)->np.ndarray:$/;"	f
extract_video_fields	package_lib/const.py	/^extract_video_fields = lambda videos, angles: [video + "_" + position + "_" + angle for video in videos$/;"	v
features	rnn_model.py	/^        features=fd['features'][:,:]$/;"	v
features_names	fnn_model.py	/^    features_names=hyperparams['features_names']$/;"	v
features_names	package_lib/dp_process_rawdata.py	/^features_names=FEATURES_FIELDS$/;"	v
features_names	package_lib/fnn_model_bk.py	/^    features_names=hyperparams['features_names']$/;"	v
fill_low_probability_data	package_lib/wearable_toolkit.py	/^    def fill_low_probability_data(self):$/;"	m	class:VideoCsvReader
fill_missing_marker	package_lib/wearable_toolkit.py	/^    def fill_missing_marker(self, calibrate_makers, motion_markers):$/;"	m	class:ViconCsvReader
find_peak_max	package_lib/wearable_toolkit.py	/^    def find_peak_max(data_clip, height, width=None, prominence=None):$/;"	m	class:SageCsvReader
forward	fnn_model.py	/^    def forward(self, inputs):$/;"	m	class:MyLSTM_MoldeV1
forward	fnn_model.py	/^    def forward(self, inputs):$/;"	m	class:MyLSTM_MoldeV2
forward	fnn_model.py	/^    def forward(self,x):# batch_size, sequence, input_size=features_dim$/;"	m	class:MyFNN_ModelV2
forward	package_lib/fnn_model_bk.py	/^    def forward(self, inputs):$/;"	m	class:MyLSTM_MoldeV1
forward	package_lib/fnn_model_bk.py	/^    def forward(self, inputs):$/;"	m	class:MyLSTM_MoldeV2
forward	package_lib/fnn_model_bk.py	/^    def forward(self,x):# batch_size, sequence, input_size=features_dim$/;"	m	class:MyFNN_ModelV2
generate_coordinate	package_lib/wearable_math.py	/^def generate_coordinate(points):$/;"	f
generate_labels_csv	package_lib/wearable_toolkit.py	/^    def generate_labels_csv(self):$/;"	m	class:ViconCsvReader
get_all_data_to_h5	package_lib/dp_load_rawdata.py	/^def get_all_data_to_h5():$/;"	f
get_angular_velocity	package_lib/wearable_toolkit.py	/^    def get_angular_velocity(self, segment, direction):$/;"	m	class:ViconCsvReader
get_angular_velocity_theta	package_lib/wearable_toolkit.py	/^    def get_angular_velocity_theta(self, segment, check_len):$/;"	m	class:ViconCsvReader
get_column_position	package_lib/wearable_toolkit.py	/^    def get_column_position(self, marker_name):$/;"	m	class:VideoCsvReader
get_data_to_h5	package_lib/dp_load_rawdata.py	/^    def get_data_to_h5(self):$/;"	m	class:V3DReader
get_data_to_h5	package_lib/dp_load_rawdata.py	/^    def get_data_to_h5(self):$/;"	m	class:ViconReader
get_data_to_h5	package_lib/dp_load_rawdata.py	/^    def get_data_to_h5(self):$/;"	m	class:XsenReader
get_data_to_h5	package_lib/dp_load_rawdata.py	/^def get_data_to_h5():$/;"	f
get_field_data	package_lib/wearable_toolkit.py	/^    def get_field_data(self, sensor, field):$/;"	m	class:SageCsvReader
get_first_event_index	package_lib/wearable_toolkit.py	/^    def get_first_event_index(self):$/;"	m	class:SageCsvReader
get_frame_range	package_lib/wearable_toolkit.py	/^    def get_frame_range(self):$/;"	m	class:ViconCsvReader
get_joint_angles	package_lib/wearable_toolkit.py	/^    def get_joint_angles(self, sub_info,joint):$/;"	m	class:ViconCsvReader
get_marker_position	package_lib/wearable_toolkit.py	/^    def get_marker_position(self, marker_name):$/;"	m	class:ViconCsvReader
get_norm	package_lib/wearable_toolkit.py	/^    def get_norm(self, sensor, field, is_plot=False):$/;"	m	class:SageCsvReader
get_relative_position	package_lib/wearable_math.py	/^def get_relative_position(origin, x_axis, y_axis, z_axis, point):$/;"	f
get_right_external_kam	package_lib/wearable_toolkit.py	/^    def get_right_external_kam(self, sub_info):$/;"	m	class:ViconCsvReader
get_rshank_angle	package_lib/wearable_toolkit.py	/^    def get_rshank_angle(self):$/;"	m	class:VideoCsvReader
get_rshank_angle	package_lib/wearable_toolkit.py	/^    def get_rshank_angle(self, direction):$/;"	m	class:ViconCsvReader
get_walking_strike_off	package_lib/wearable_toolkit.py	/^    def get_walking_strike_off(self, strike_delay, off_delay, segment, cut_off_fre_strike_off=None,$/;"	m	class:SageCsvReader
get_world_position	package_lib/wearable_math.py	/^def get_world_position(origin, x_axis, y_axis, z_axis, relative_point):$/;"	f
gpus	rnn_model.py	/^gpus=tf.config.list_logical_devices(device_type='GPU')$/;"	v
hyperparams	fnn_model.py	/^hyperparams={$/;"	v
hyperparams	package_lib/dp_process_rawdata.py	/^hyperparams={$/;"	v
hyperparams	package_lib/fnn_model_bk.py	/^hyperparams={$/;"	v
hyperparams	rnn_model.py	/^    hyperparams=initParameters()$/;"	v
initParameters	rnn_model.py	/^def initParameters():$/;"	f
inverse_norm	package_lib/dp_process_rawdata.py	/^def inverse_norm(norm_datasets:np.ndarray, col_names:list, norm_type:str)->np.ndarray:$/;"	f
inverse_norm	package_lib/fnn_model_bk.py	/^def inverse_norm(norm_datasets:np.ndarray, col_names:list, norm_type:str)->np.ndarray:$/;"	f
is_qualified_ron_event	package_lib/wearable_toolkit.py	/^    def is_qualified_ron_event(ron_i):$/;"	f	function:translate_step_event_to_step_id
labels	rnn_model.py	/^        labels=fd['labels'][:,:]$/;"	v
labels_names	fnn_model.py	/^    labels_names=hyperparams['labels_names']$/;"	v
labels_names	package_lib/dp_process_rawdata.py	/^labels_names=LABELS_FIELDS$/;"	v
labels_names	package_lib/fnn_model_bk.py	/^    labels_names=hyperparams['labels_names']$/;"	v
load_normalize_data	package_lib/dp_process_rawdata.py	/^def load_normalize_data(hyperparams,scaler=None,**args):$/;"	f
load_test_datasets	package_lib/dp_process_rawdata.py	/^def load_test_datasets(test_datasets_range:list,norm_type='max_min',raw_datasets_path=".\/datasets_files\/raw_datasets.hdf5")->zip:$/;"	f
load_test_datasets	package_lib/fnn_model_bk.py	/^def load_test_datasets(test_datasets_range:list,norm_type='max_min',raw_datasets_path=".\/datasets_files\/raw_datasets.hdf5")->zip:$/;"	f
low_pass_filtering	package_lib/wearable_toolkit.py	/^    def low_pass_filtering(self, cut_off_fre, sampling_fre, filter_order):$/;"	m	class:VideoCsvReader
main	ptags.py	/^def main():$/;"	f
main	rnn_model.py	/^def main():$/;"	f
matcher	ptags.py	/^matcher = re.compile(expr)$/;"	v
model	fnn_model.py	/^        model=MyLSTM_MoldeV1(input_size=2, hidden_size=num_labels, num_layers=2, output_size=num_labels,device=device)# input_size=number of IMU$/;"	v
model	package_lib/fnn_model_bk.py	/^        model=MyFNN_ModelV2(num_features,num_labels)$/;"	v
model_forecast	rnn_model.py	/^def model_forecast(model, series, hyperparams):$/;"	f
model_v1	rnn_model.py	/^def model_v1(hyperparams):$/;"	f
model_v2	rnn_model.py	/^def model_v2():$/;"	f
multi_subject_data	package_lib/dp_process_rawdata.py	/^    multi_subject_data=[]$/;"	v
myCallback	rnn_model.py	/^class myCallback(tf.keras.callbacks.Callback):$/;"	c
norm_datasets	package_lib/dp_process_rawdata.py	/^def norm_datasets(datasets:np.ndarray,col_names:str,norm_type='mean_std')->np.ndarray:$/;"	f
norm_datasets	package_lib/fnn_model_bk.py	/^def norm_datasets(datasets:np.ndarray,col_names:str,norm_type='mean_std')->np.ndarray:$/;"	f
norm_type	fnn_model.py	/^    norm_type=hyperparams['norm_type']$/;"	v
norm_type	package_lib/fnn_model_bk.py	/^    norm_type=hyperparams['norm_type']$/;"	v
normalization_parameters	package_lib/dp_process_rawdata.py	/^def normalization_parameters(row_idx,col_names,datarange="all_subject", norm_type="mean_std", raw_datasets_path=".\/datasets_files\/raw_datasets.hdf5"):$/;"	f
normalization_parameters	package_lib/fnn_model_bk.py	/^def normalization_parameters(row_idx,col_names,datarange="all_subject", norm_type="mean_std", raw_datasets_path=".\/datasets_files\/raw_datasets.hdf5"):$/;"	f
normalize_subjects_data	rnn_model.py	/^def normalize_subjects_data(hyperparams):$/;"	f
num_features	fnn_model.py	/^    num_features=len(features_names)$/;"	v
num_features	package_lib/fnn_model_bk.py	/^    num_features=len(features_names)$/;"	v
num_labels	fnn_model.py	/^    num_labels=len(labels_names)$/;"	v
num_labels	package_lib/fnn_model_bk.py	/^    num_labels=len(labels_names)$/;"	v
on_epoch_end	rnn_model.py	/^    def on_epoch_end(self, epcoh, logs={}):$/;"	m	class:myCallback
partial_fit	package_lib/wearable_toolkit.py	/^    def partial_fit(self, X, y=None):$/;"	m	class:DivideMaxScalar
plot_history	rnn_model.py	/^def plot_history(history_dict):$/;"	f
plot_prediction	rnn_model.py	/^def plot_prediction(features,labels,predictions,testing_folder):$/;"	f
plot_prediction_statistic	rnn_model.py	/^def plot_prediction_statistic(features, labels, predictions,testing_folder):$/;"	f
plot_statistic_kneemoment_under_fpa	package_lib/dp_process_rawdata.py	/^def plot_statistic_kneemoment_under_fpa(data: list,subjects: list):$/;"	f
plot_test_results	package_lib/dp_process_rawdata.py	/^def plot_test_results(features,labels,predictions,features_names,labels_names,fig_save_folder=None,**args):$/;"	f
plot_test_results	package_lib/fnn_model_bk.py	/^def plot_test_results(features,labels,predictions,features_names,labels_names,fig_save_folder=None,**args):$/;"	f
predictions	rnn_model.py	/^        predictions=fd['predictions'][:,:]$/;"	v
raw_dataset_path	package_lib/dp_process_rawdata.py	/^raw_dataset_path=os.path.join(DATA_PATH,'features_labels_rawdatasets.hdf5')$/;"	v
raw_datasets_path	fnn_model.py	/^    raw_datasets_path=hyperparams['raw_datasets_path']$/;"	v
raw_datasets_path	package_lib/fnn_model_bk.py	/^    raw_datasets_path=hyperparams['raw_datasets_path']$/;"	v
read_rawdata	package_lib/dp_process_rawdata.py	/^def read_rawdata(row_idx: int,col_names: list,raw_datasets_path=None,**args)-> numpy.ndarray:$/;"	f
read_rawdata	package_lib/fnn_model_bk.py	/^def read_rawdata(row_idx: int,col_names: list,raw_datasets_path=".\/datasets_files\/raw_datasets.hdf5")-> numpy.ndarray:$/;"	f
reading	package_lib/wearable_toolkit.py	/^    def reading(file_path):$/;"	m	class:ViconCsvReader
resample_to_100hz	package_lib/wearable_toolkit.py	/^    def resample_to_100hz(self):$/;"	m	class:VideoCsvReader
rigid_transform_3d	package_lib/wearable_toolkit.py	/^def rigid_transform_3d(a, b):$/;"	f
rotation_matrix_to_euler_angles	package_lib/wearable_toolkit.py	/^def rotation_matrix_to_euler_angles(R):$/;"	f
save_testResult	rnn_model.py	/^def save_testResult(features,labels,predictions,testing_folder):$/;"	f
save_trainedModel	rnn_model.py	/^def save_trainedModel(trained_model,history_dict,training_folder,**args):$/;"	f
save_training_process	package_lib/dp_process_rawdata.py	/^def save_training_process(training_folder, loss):$/;"	f
save_training_process	package_lib/fnn_model_bk.py	/^def save_training_process(training_folder, loss):$/;"	f
save_training_results	package_lib/dp_process_rawdata.py	/^def save_training_results(training_folder, model, loss):$/;"	f
save_training_results	package_lib/fnn_model_bk.py	/^def save_training_results(training_folder, model, loss):$/;"	f
setHyperparams_subject	package_lib/dp_process_rawdata.py	/^def setHyperparams_subject(hyperparaams):$/;"	f
split_dataset	rnn_model.py	/^def split_dataset(scaled_series,sub_idx):$/;"	f
sub_idx	fnn_model.py	/^        sub_idx=0$/;"	v
sub_idx	package_lib/fnn_model_bk.py	/^        sub_idx=0$/;"	v
sub_name	package_lib/dp_process_rawdata.py	/^sub_name='P_09_libang'$/;"	v
subject_idx_name	package_lib/dp_process_rawdata.py	/^                subject_idx_name=subject_name$/;"	v
subject_infos	package_lib/dp_load_rawdata.py	/^subject_infos = pd.read_csv(os.path.join(DATA_PATH, 'subject_info.csv'), index_col=0)$/;"	v
subject_infos	package_lib/dp_process_rawdata.py	/^    subject_infos = pd.read_csv(os.path.join(DATA_PATH, 'subject_info.csv'), index_col=0)$/;"	v
subject_infos	rnn_model.py	/^subject_infos = pd.read_csv(os.path.join(DATA_PATH, 'subject_info.csv'), index_col=0)$/;"	v
subject_names	package_lib/dp_process_rawdata.py	/^    subject_names=[ss for ss in subject_infos.index]$/;"	v
subjects_list	package_lib/dp_process_rawdata.py	/^    subjects_list=['P_08','P_09','P_10', 'P_11', 'P_13', 'P_14', 'P_15','P_16','P_17','P_18','P_19','P_20','P_21','P_22','P_23', 'P_24']$/;"	v
sync_via_correlation	package_lib/wearable_toolkit.py	/^def sync_via_correlation(data1, data2, verbose=False):$/;"	f
tags	ptags.py	/^tags = []    # Modified global variable!$/;"	v
test_loader	fnn_model.py	/^        test_loader = torch.utils.data.DataLoader(dataset=test_sets, batch_size=batch_size, shuffle=False)$/;"	v
test_loader	package_lib/fnn_model_bk.py	/^        test_loader = torch.utils.data.DataLoader(dataset=test_sets, batch_size=batch_size, shuffle=False)$/;"	v
test_model	fnn_model.py	/^def test_model(training_folder:str,test_loader,load_model_manner='whole_model',**args)->np.ndarray:$/;"	f
test_model	package_lib/fnn_model_bk.py	/^def test_model(training_folder:str,test_loader,load_model_manner='whole_model',**args)->np.ndarray:$/;"	f
test_model	rnn_model.py	/^def test_model(training_folder, xy_test,scaler,**args):$/;"	f
test_sets	fnn_model.py	/^        test_sets=torch.utils.data.Subset(datasets,indices_test)$/;"	v
test_sets	package_lib/fnn_model_bk.py	/^        test_sets=torch.utils.data.Subset(datasets,indices_test)$/;"	v
testing_folder	rnn_model.py	/^        testing_folder=os.path.join(EXPERIMENT_RESULTS_PATH,'models_parameters_results\/2021-09-28\/test_191409\/test_1')$/;"	v
testing_folder	rnn_model.py	/^testing_folder='.\/model\/test_2020'$/;"	v
testing_results	rnn_model.py	/^    testing_results=testing_folder+'\/test_results.h5'$/;"	v
train_loader	fnn_model.py	/^        train_loader = torch.utils.data.DataLoader(dataset=train_sets, batch_size=batch_size, shuffle=True)$/;"	v
train_loader	package_lib/fnn_model_bk.py	/^        train_loader = torch.utils.data.DataLoader(dataset=train_sets, batch_size=batch_size, shuffle=True)$/;"	v
train_model	fnn_model.py	/^def train_model(model,hyperparams, train_loader,eval_loader):$/;"	f
train_model	package_lib/fnn_model_bk.py	/^def train_model(model,hyperparams, train_loader,eval_loader):$/;"	f
train_model	rnn_model.py	/^def train_model(model,hyperparams,train_set,valid_set,training_mode='Integrative_way'):$/;"	f
train_model_v2	rnn_model.py	/^def train_model_v2():$/;"	f
train_sets	fnn_model.py	/^        train_sets=torch.utils.data.Subset(datasets,indices_train)$/;"	v
train_sets	package_lib/fnn_model_bk.py	/^        train_sets=torch.utils.data.Subset(datasets,indices_train)$/;"	v
training_folder	fnn_model.py	/^        training_folder=train_model(model,hyperparams,train_loader,eval_loader)$/;"	v
training_folder	package_lib/fnn_model_bk.py	/^        training_folder=train_model(model,hyperparams,train_loader,eval_loader)$/;"	v
training_folder	rnn_model.py	/^training_folder=testing_folder+"\/..\/training_"+re.search(r"\\d+$",testing_folder).group()$/;"	v
transform	package_lib/wearable_toolkit.py	/^    def transform(self, X):$/;"	m	class:DivideMaxScalar
transform_to_step_events	package_lib/wearable_toolkit.py	/^    def transform_to_step_events(ron_i):$/;"	f	function:translate_step_event_to_step_id
translate_step_event_to_step_id	package_lib/wearable_toolkit.py	/^def translate_step_event_to_step_id(events_dict, max_step_length):$/;"	f
treat_file	ptags.py	/^def treat_file(filename):$/;"	f
windowed_dataset	rnn_model.py	/^def windowed_dataset(series, hyperparams,shuffle_buffer):$/;"	f
