{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c83ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import package_lib.const as const\n",
    "\n",
    "import package_lib.wearable_toolkit as wearable_toolkit\n",
    "import package_lib.wearable_math as wearable_math\n",
    "import h5py\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import pdb\n",
    "\n",
    "from package_lib.const import SEGMENT_DEFINITIONS, SUBJECTS, STATIC_TRIALS, TRIALS, SESSIONS, DATA_PATH, \\\n",
    "SUBJECT_HEIGHT, SUBJECT_WEIGHT, SUBJECT_ID, TRIAL_ID, XSEN_IMU_ID, IMU_DATA_FIELDS, FORCE_DATA_FIELDS,\\\n",
    "KNEE_DATA_FIELDS\n",
    "\n",
    "subject_infos = pd.read_csv(os.path.join(DATA_PATH, 'subject_info.csv'), index_col=0)\n",
    "\n",
    "class XsenReader():\n",
    "    def __init__(self,subject,session):\n",
    "        self.subject=subject\n",
    "        self.session=session\n",
    "        self.folder_path=os.path.join(DATA_PATH, subject,session, 'Xsen')\n",
    "        self.get_Xsen_data_to_csv()\n",
    "        \n",
    "    def get_Xsen_data_to_csv(self):\n",
    "        folder_path=self.folder_path\n",
    "        # transfer Xsen data in several txt files (four files) into a csv file\n",
    "        is_verbose=False\n",
    "        self.Xsen_data={}\n",
    "        for trial in TRIALS:\n",
    "            file_name='MT_'+XSEN_IMU_ID['MASTER']+'_0'+trial+'-000_'+XSEN_IMU_ID['L_THIGH']+'.txt'\n",
    "            file_path=os.path.join(folder_path,file_name)\n",
    "            if is_verbose:\n",
    "                print(file_path)\n",
    "            l_thigh_txt=np.loadtxt(file_path,comments='//',skiprows=6,dtype=float)\n",
    "            \n",
    "            \n",
    "            file_name='MT_'+XSEN_IMU_ID['MASTER']+'_0'+trial+'-000_'+XSEN_IMU_ID['L_SHANK']+'.txt'\n",
    "            file_path=os.path.join(folder_path,file_name)\n",
    "            if is_verbose:\n",
    "                print(file_path)\n",
    "            l_shank_txt=np.loadtxt(file_path,comments='//',skiprows=6,dtype=float)\n",
    "            \n",
    "            file_name='MT_'+XSEN_IMU_ID['MASTER']+'_0'+trial+'-000_'+XSEN_IMU_ID['R_THIGH']+'.txt'\n",
    "            file_path=os.path.join(folder_path,file_name)\n",
    "            if is_verbose:\n",
    "                print(file_path)\n",
    "            r_thigh_txt=np.loadtxt(file_path,comments='//',skiprows=6,dtype=float)\n",
    "            \n",
    "            \n",
    "            file_name='MT_'+XSEN_IMU_ID['MASTER']+'_0'+trial+'-000_'+XSEN_IMU_ID['L_SHANK']+'.txt'\n",
    "            file_path=os.path.join(folder_path,file_name)\n",
    "            if is_verbose:\n",
    "                print(file_path)\n",
    "            r_shank_txt=np.loadtxt(file_path,comments='//',skiprows=6,dtype=float)\n",
    "            \n",
    "            all_imu_data=np.hstack((l_thigh_txt,l_shank_txt[:,1:]))\n",
    "            all_imu_data=np.hstack((all_imu_data,r_thigh_txt[:,1:]))\n",
    "            all_imu_data=np.hstack((all_imu_data,r_shank_txt[:,1:]))\n",
    "            \n",
    "            pd_all_imu_data=pd.DataFrame(data=all_imu_data,columns=IMU_DATA_FIELDS)\n",
    "            \n",
    "            csv_path=os.path.join(folder_path,'features'+'_trial_'+trial+'.csv')\n",
    "            if is_verbose:\n",
    "                print(csv_path)\n",
    "            pd_all_imu_data.to_csv(csv_path,index=False)\n",
    "            \n",
    "            self.Xsen_data[trial]=pd_all_imu_data\n",
    "            #pd._to_csv()\n",
    "            \n",
    "    def get_Xsen_data_to_h5(self):\n",
    "        \n",
    "        # remove the exist h5 file\n",
    "        h5format_dataset=os.path.join(self.folder_path,'features_rawdataset.hdf5')\n",
    "        if os.path.exists(h5format_dataset):\n",
    "            try:\n",
    "                os.remove(h5format_dataset)\n",
    "            except IOError:\n",
    "                print(\"cannot remove h5 file\")\n",
    "    \n",
    "        # save the h5 file\n",
    "        f = h5py.File(h5format_dataset, \"w\")\n",
    "        f.attrs['columns']=list(self.Xsen_data['01'].columns)\n",
    "        sub=f.create_group(self.subject)\n",
    "        for trial in TRIALS:\n",
    "            sub.create_dataset(trial,data=self.Xsen_data[trial])\n",
    "        f.close()\n",
    " \n",
    "\n",
    "class ViconReader():\n",
    "    def __init__(self,subject,session,subject_info):\n",
    "        vicon_calibrate_data_path = os.path.join(DATA_PATH, subject, session, subject+' Cal '+'00' + '.csv')\n",
    "        self.vicon_data={}\n",
    "        self.subject=subject\n",
    "        self.folder_path=os.path.join(DATA_PATH,subject,session)\n",
    "        for trial in TRIALS:\n",
    "            vicon_data_path = os.path.join(self.folder_path, subject +' Cal '+trial + '.csv')\n",
    "            self.vicon_data[trial]=wearable_toolkit.ViconCsvReader(vicon_data_path,SEGMENT_DEFINITIONS,vicon_calibrate_data_path,subject_info)\n",
    "            \n",
    "        self.get_vicon_data_to_h5()\n",
    "        \n",
    "    def get_vicon_data_to_h5(self):\n",
    "        \n",
    "        # remove the exist h5 file\n",
    "        h5format_dataset=os.path.join(self.folder_path,'labels_rawdataset.hdf5')\n",
    "        if os.path.exists(h5format_dataset):\n",
    "            try:\n",
    "                os.remove(h5format_dataset)\n",
    "            except IOError:\n",
    "                print(\"cannot remove h5 file\")\n",
    "    \n",
    "        # save the h5 file\n",
    "        f = h5py.File(h5format_dataset, \"w\")\n",
    "        f.attrs['columns']=list(self.vicon_data['01'].data_frame.columns)\n",
    "        sub=f.create_group(self.subject)\n",
    "        for trial in TRIALS:\n",
    "            sub.create_dataset(trial,data=self.vicon_data[trial].data_frame)\n",
    "            #print(self.vicon_data[trial].data_frame.head())\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "\n",
    "def get_data_to_h5():\n",
    "    for subject in SUBJECTS:\n",
    "        for session in SESSIONS:\n",
    "            print(\"Subject {}, Session {}\".format(subject,session))\n",
    "            # process IMU data\n",
    "            xsen=XsenReader(subject,session)\n",
    "            xsen.get_Xsen_data_to_h5()\n",
    "            # process vicon data\n",
    "            subject_info = subject_infos.loc[subject, :]\n",
    "            vicon=ViconReader(subject, session, subject_info)\n",
    "                \n",
    "def get_all_data_to_h5():\n",
    "    # declare h5 file\n",
    "    h5format_dataset=os.path.join(DATA_PATH,\"features_lables_rawdatasets.hdf5\")\n",
    "    \n",
    "    # remove the exist h5 file\n",
    "    if os.path.exists(h5format_dataset):\n",
    "        try:\n",
    "            os.remove(h5format_dataset)\n",
    "        except IOError:\n",
    "            print(\"cannot remove h5 file\")\n",
    "            \n",
    "    # save the h5 file\n",
    "    with h5py.File(h5format_dataset, \"w\") as f:\n",
    "        features_data={}\n",
    "        for subject in SUBJECTS:\n",
    "            sub=f.create_group(subject)\n",
    "            f.attrs['subjects']=SUBJECTS\n",
    "            for session in SESSIONS:\n",
    "                features_path=os.path.join(DATA_PATH,subject,session,'Xsen','features_rawdataset.hdf5')\n",
    "                labels_path=os.path.join(DATA_PATH,subject,session,'labels_rawdataset.hdf5')\n",
    "                with h5py.File(features_path,'r') as ff:\n",
    "                    with h5py.File(labels_path,'r') as fl:\n",
    "                        for trial in TRIALS:\n",
    "                            #pdb.set_trace()\n",
    "                            features_labels=pd.concat([pd.DataFrame(ff[subject][trial]),pd.DataFrame(fl[subject][trial])],axis=1)\n",
    "                            sub.create_dataset(trial,data=features_labels)\n",
    "                        pdb.set_trace()\n",
    "                        sub.attrs['columns']=list(ff.attrs['columns'])+list(fl.attrs['columns'])\n",
    "    \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    get_all_data_to_h5()\n",
    "    #get_data_to_h5()\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c2bb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "a=['1','2']\n",
    "b=['3','4','5']\n",
    "c=a+b\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
