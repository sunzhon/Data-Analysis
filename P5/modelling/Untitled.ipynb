{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45dceb79",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e0ab28534978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#trainimgs, trainlabels, testimgs, testlabels = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#获取训练数据个数，测试集数据个数，图像维度和类别数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mntrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclasses\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mntrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow_datasets\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import os\n",
    "import math\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "#导入mnist数据\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#mnist = input_data.read_data_sets('MNIST_data',one_hot=True)#one_hot=True 表示 数据的标签是one_hot编码的，即数据标签为1*10的数组\n",
    "#读取训练数据，训练标签，测试数据，测试标签\n",
    "#trainimgs, trainlabels, testimgs, testlabels = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels \n",
    "#获取训练数据个数，测试集数据个数，图像维度和类别数\n",
    "ntrain, ntest, dim, nclasses  = train_images.shape[0], test_images.shape[0], train_images.shape[1], train_labels.shape[1]\n",
    "print (ntrain, ntest, dim, nclasses)\n",
    " \n",
    "#这里插入一段，实际执行时可以跳过：如果你想看看这些handwriting的数字到底长什么样，那么可以执行下面的代码：\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "mnist = tensorflow_datasets.load('mnist')\n",
    "\n",
    "#mnist = input_data.read_data_sets('MNIST_data')\n",
    " \n",
    "examples_n = 100 # display some images\n",
    "indexes = np.random.choice(range(mnist.train.images.shape[0]), examples_n, replace=False)\n",
    " \n",
    "fig = plt.figure(figsize=(5,5))\n",
    " \n",
    "for i in range(1, examples_n + 1):\n",
    "    a = fig.add_subplot(np.sqrt(examples_n), np.sqrt(examples_n), i)\n",
    "    a.axis('off')\n",
    "    image = mnist.train.images[indexes[i-1]].reshape((28, 28))\n",
    "    a.imshow(image, cmap='Greys_r');\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf07b0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-abe28b1f86cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "max_features = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1370ad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1c0f5d8c04ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# LSTM weather prediction demo\n",
    "# Written by: Dan R 2020\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "# Core Keras libraries\n",
    "#\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    " \n",
    "#\n",
    "# For data conditioning\n",
    "#\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "#\n",
    "# Make results reproducible\n",
    "#\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "#from tensorflow import set_random_seed\n",
    "#set_random_seed(1)\n",
    "\n",
    "\n",
    "# \n",
    "# Other essential libraries\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from numpy import array\n",
    "\n",
    "# Make our plot a bit formal\n",
    "font = {'family' : 'Arial',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Set input number of timestamps and training days\n",
    "#\n",
    "n_timestamp = 10\n",
    "train_days = 1500  # number of days to train from\n",
    "testing_days = 500 # number of days to be predicted\n",
    "n_epochs = 25\n",
    "filter_on = 1\n",
    "\n",
    "\n",
    "#\n",
    "# Select model type\n",
    "# 1: Single cell\n",
    "# 2: Stacked\n",
    "# 3: Bidirectional\n",
    "#\n",
    "model_type = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/danrustia11/WeatherLSTM/master/data/weather_temperature_yilan.csv\"\n",
    "dataset = pd.read_csv(url)\n",
    "if filter_on == 1:\n",
    "    dataset['Temperature'] = medfilt(dataset['Temperature'], 3)\n",
    "    dataset['Temperature'] = gaussian_filter1d(dataset['Temperature'], 1.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Set number of training and testing data\n",
    "# \n",
    "train_set = dataset[0:train_days].reset_index(drop=True)\n",
    "test_set = dataset[train_days: train_days+testing_days].reset_index(drop=True)\n",
    "training_set = train_set.iloc[:, 1:2].values\n",
    "testing_set = test_set.iloc[:, 1:2].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Normalize data first\n",
    "#\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "testing_set_scaled = sc.fit_transform(testing_set)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Split data into n_timestamp\n",
    "#\n",
    "def data_split(sequence, n_timestamp):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_timestamp\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # i to end_ix as input\n",
    "        # end_ix as target output\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "\n",
    "X_train, y_train = data_split(training_set_scaled, n_timestamp)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test, y_test = data_split(testing_set_scaled, n_timestamp)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if model_type == 1:\n",
    "    # Single cell LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 50, activation='relu',input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Dense(units = 1))\n",
    "if model_type == 2:\n",
    "    # Stacked LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "if model_type == 3:\n",
    "    # Bidirectional LSTM\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Start training\n",
    "#\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "history = model.fit(X_train, y_train, epochs = n_epochs, batch_size = 32)\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(loss))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Get predicted data\n",
    "#\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "#\n",
    "# 'De-normalize' the data\n",
    "#\n",
    "y_predicted_descaled = sc.inverse_transform(y_predicted)\n",
    "y_train_descaled = sc.inverse_transform(y_train)\n",
    "y_test_descaled = sc.inverse_transform(y_test)\n",
    "y_pred = y_predicted.ravel()\n",
    "y_pred = [round(yx, 2) for yx in y_pred]\n",
    "y_tested = y_test.ravel()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Show results\n",
    "#\n",
    "plt.figure(figsize=(8,7))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(dataset['Temperature'], color = 'black', linewidth=1, label = 'True value')\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title(\"All data\")\n",
    "\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot(y_test_descaled, color = 'black', linewidth=1, label = 'True value')\n",
    "plt.plot(y_predicted_descaled, color = 'red',  linewidth=1, label = 'Predicted')\n",
    "plt.legend(frameon=False)\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title(\"Predicted data (n days)\")\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot(y_test_descaled[0:75], color = 'black', linewidth=1, label = 'True value')\n",
    "plt.plot(y_predicted_descaled[0:75], color = 'red', label = 'Predicted')\n",
    "plt.legend(frameon=False)\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title(\"Predicted data (first 75 days)\")\n",
    "\n",
    "plt.subplot(3, 3, 7)\n",
    "plt.plot(epochs, loss, color='black')\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Training curve\")\n",
    "\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.plot(y_test_descaled-y_predicted_descaled, color='black')\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title(\"Residual plot\")\n",
    "\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.scatter(y_predicted_descaled, y_test_descaled, s=2, color='black')\n",
    "plt.ylabel(\"Y true\")\n",
    "plt.xlabel(\"Y predicted\")\n",
    "plt.title(\"Scatter plot\")\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.5, wspace=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test_descaled, y_predicted_descaled)\n",
    "r2 = r2_score(y_test_descaled, y_predicted_descaled)\n",
    "print(\"mse=\" + str(round(mse,2)))\n",
    "print(\"r2=\" + str(round(r2,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
