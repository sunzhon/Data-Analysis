{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c16a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8b80a",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c600e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.79476622]\n",
      "   L_Up_Quat_q0  L_Up_Quat_q1  L_Up_Quat_q2  L_Up_Quat_q3  L_Lower_Quat_q0  \\\n",
      "0      0.054888      0.098097      0.076217      0.132996         0.031749   \n",
      "\n",
      "   L_Lower_Quat_q1  L_Lower_Quat_q2  L_Lower_Quat_q3  \n",
      "0         0.123713          0.05695          0.10984  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import numpy\n",
    "\n",
    "\n",
    "def read_rawdata(row_idx: int,col_names: list)-> numpy.ndarray:\n",
    "    \"\"\"\n",
    "    @Description:\n",
    "    To read the data from h5 file and normalize the features and labels.\n",
    "    @Parameters:\n",
    "    Row_idx: the index of row. data type is int\n",
    "    Col_names: the names of columns. data type is string\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File('raw_datasets.hdf5', 'r') as fd:\n",
    "        ## The coloms of the features and labels\n",
    "        keys=list(fd.keys())\n",
    "        columns=fd[keys[0]].attrs.get('columns')\n",
    "        col_idxs=[]\n",
    "        for col_name in col_names:\n",
    "            col_idxs.append(np.argwhere(columns==col_name)[0][0])\n",
    "        \n",
    "        data_len_list=[]\n",
    "        for idx in range(len(fd.keys())):\n",
    "            key=\"sub_\"+str(idx)\n",
    "            #print(key)\n",
    "            data_len_list.append(len(fd[key]))\n",
    "        \n",
    "        data_len_list_sum=[]\n",
    "        sum_num=0\n",
    "        for num in data_len_list:\n",
    "            sum_num+=num\n",
    "            data_len_list_sum.append(sum_num)\n",
    "        \n",
    "        data_len_list_sum=np.array(data_len_list_sum)\n",
    "        \n",
    "        sub_idx=np.argwhere(data_len_list_sum > row_idx)[0,0]\n",
    "        if(sub_idx>0):\n",
    "            row_idx=row_idx-data_len_list_sum[sub_idx-1]\n",
    "            \n",
    "        return fd['sub_'+str(sub_idx)][row_idx,col_idxs]\n",
    "    \n",
    "    \n",
    "\n",
    "def normalization_parameters(row_idx,col_names):\n",
    "    with h5py.File('raw_datasets.hdf5', 'r') as fd:\n",
    "        keys=list(fd.keys())# the keys/columns name of the datafile \n",
    "        columns=fd[keys[0]].attrs.get('columns')\n",
    "        col_idxs=[]\n",
    "        for col_name in col_names:\n",
    "            col_idxs.append(np.argwhere(columns==col_name)[0][0])\n",
    "    \n",
    "        data_len_list=[]\n",
    "        for idx in range(len(fd.keys())):\n",
    "            key=\"sub_\"+str(idx)\n",
    "            data_len_list.append(len(fd[key]))\n",
    "    \n",
    "        data_len_list_sum=[]\n",
    "        sum_num=0\n",
    "        for num in data_len_list:\n",
    "            sum_num+=num\n",
    "            data_len_list_sum.append(sum_num)\n",
    "    \n",
    "        data_len_list_sum=np.array(data_len_list_sum)\n",
    "    \n",
    "        sub_idx=np.argwhere(data_len_list_sum > row_idx)[0,0]\n",
    "        if(sub_idx>0):\n",
    "            row_idx=row_idx-data_len_list_sum[sub_idx-1]\n",
    "            sub_idx=np.argwhere(data_len_list_sum > row_idx)[0,0]\n",
    "            if(sub_idx>0):\n",
    "                row_idx=row_idx-data_len_list_sum[sub_idx-1]\n",
    "        \n",
    "        mean=np.mean(fd['sub_'+str(sub_idx)][:,col_idxs],axis=0,keepdims=True)\n",
    "        std=np.std(fd['sub_'+str(sub_idx)][:,col_idxs],axis=0,keepdims=True)\n",
    "        data_mean=pd.DataFrame(data=mean,columns=col_names)\n",
    "        data_std=pd.DataFrame(data=std,columns=col_names)\n",
    "        return data_mean, data_std    \n",
    "        \n",
    "\n",
    "features_names=['L_Up_Quat_q0', 'L_Up_Quat_q1', 'L_Up_Quat_q2', 'L_Up_Quat_q3','L_Lower_Quat_q0', 'L_Lower_Quat_q1', 'L_Lower_Quat_q2', 'L_Lower_Quat_q3']\n",
    "print(read_rawdata(20000,['R_IE']))\n",
    "data_mean, data_std = normalization_parameters(200,features_names)    \n",
    "print(data_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08bea32",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9ad7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用某日前8天窗口数据作为输入预测该日数据\n",
    "class DroplandingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,datafile,features_names,labels_names,train=True):\n",
    "        with h5py.File(datafile,'r') as fd:\n",
    "            keys=fd.keys()\n",
    "            ## features and labels\n",
    "            keys=list(fd.keys())\n",
    "            #print(f.attrs[\"columns\"]\n",
    "            columns=fd[keys[0]].attrs.get('columns')\n",
    "            '''\n",
    "            features_names=['L_Up_Quat_q0', 'L_Up_Quat_q1', 'L_Up_Quat_q2', 'L_Up_Quat_q3',\n",
    "                        'L_Lower_Quat_q0', 'L_Lower_Quat_q1', 'L_Lower_Quat_q2', 'L_Lower_Quat_q3']\n",
    "            labels_names=['R_IE']\n",
    "            '''\n",
    "            \n",
    "            # 16 features and 6 lables/targets\n",
    "            # features and labels idx\n",
    "            features_idx=[]\n",
    "            labels_idx=[]\n",
    "            for f_name in features_names:\n",
    "                features_idx.append(np.argwhere(columns==f_name)[0,0])\n",
    "            for l_name in labels_names:\n",
    "                labels_idx.append(np.argwhere(columns==l_name)[0,0])\n",
    "                \n",
    "            #row_length and row_idx\n",
    "            data_len_list=[]\n",
    "            self.all_datasets={}\n",
    "            for idx in range(len(fd.keys())):\n",
    "                key=\"sub_\"+str(idx)\n",
    "                data_len_list.append(len(fd[key]))\n",
    "                temp_data=np.array(fd[key])\n",
    "                #Normalization maunually or by sci-kit learn tools 正则化\n",
    "                temp_mean = np.mean(temp_data,axis=0,keepdims=True)\n",
    "                temp_std = np.std(temp_data,axis=0,keepdims=True)\n",
    "                temp_data=(temp_data-temp_mean)/temp_std\n",
    "                self.all_datasets[key]=temp_data\n",
    "                \n",
    "            \n",
    "            #summary data length\n",
    "            data_len_list_sum=[]\n",
    "            sum_num=0\n",
    "            for num in data_len_list:\n",
    "                sum_num+=num\n",
    "                data_len_list_sum.append(sum_num)\n",
    "        \n",
    "            data_len_list_sum=np.array(data_len_list_sum)\n",
    "            \n",
    "            #class attrs\n",
    "            self.data_len=sum_num\n",
    "            self.features_idx=features_idx\n",
    "            self.labels_idx=labels_idx\n",
    "            self.data_len_list_sum=data_len_list_sum\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        #print(self.data_len)\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self,row_idx):       \n",
    "        #The index of the subjects \n",
    "        sub_idx=np.argwhere(self.data_len_list_sum>row_idx)[0,0]\n",
    "        if(sub_idx>0):\n",
    "            row_idx=row_idx-self.data_len_list_sum[sub_idx-1]\n",
    "        \n",
    "        #Features and labels\n",
    "        features = self.all_datasets['sub_'+str(sub_idx)][row_idx,self.features_idx]\n",
    "        labels = self.all_datasets['sub_'+str(sub_idx)][row_idx,self.labels_idx]    \n",
    "        \n",
    "        #print(\"feature type:{} and shape:{}\".format(type(features),features.shape))\n",
    "        return (torch.from_numpy(features).to(torch.float32),torch.from_numpy(labels).to(torch.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#数据较小，可以将全部训练数据放入到一个batch中，提升性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47eecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db1: 50000 db2: 10000 db3: 36983\n",
      "<torch.utils.data.dataset.Subset object at 0x7fe5b1f1d790>\n",
      "(tensor([-1.6803, -1.5251, -1.0952, -0.6839,  0.3138, -1.4842,  1.3588, -1.1769,\n",
      "        -1.2196, -0.7489,  1.5130, -1.8104,  1.4317,  0.8999, -1.8080,  2.4890]), tensor([ 1.3567, -0.1019,  0.2192, -0.0622, -2.0871,  0.8768]))\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "h5format_dataset=\"raw_datasets.hdf5\"\n",
    "\n",
    "transforms_dic={\"features\": transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.0)*16,(1.0)*16)]),\n",
    "               \"labels\": transforms.Compose([transforms.ToTensor,transforms.Normalize((0.0)*6,(1.0)*6)])}\n",
    "#datasets = DroplandingDataset(h5format_dataset,transform=transforms_dic['features'],target_transform=transforms_dic['labels'])\n",
    "\n",
    "features_names=['L_Up_Quat_q0', 'L_Up_Quat_q1', 'L_Up_Quat_q2', 'L_Up_Quat_q3',\n",
    "                        'L_Lower_Quat_q0', 'L_Lower_Quat_q1', 'L_Lower_Quat_q2', 'L_Lower_Quat_q3',\n",
    "                        'R_Up_Quat_q0', 'R_Up_Quat_q1', 'R_Up_Quat_q2', 'R_Up_Quat_q3',\n",
    "                       'R_Lower_Quat_q0', 'R_Lower_Quat_q1', 'R_Lower_Quat_q2', 'R_Lower_Quat_q3']\n",
    "labels_names=['R_IE', 'R_AA', 'R_FE', 'L_IE', 'L_AA', 'L_FE']\n",
    "\n",
    "datasets=DroplandingDataset(h5format_dataset,features_names,labels_names)\n",
    "train_sets, val_sets, test_sets=torch.utils.data.random_split(datasets,[50000,10000,36983])\n",
    "print(\"db1:\",len(train_sets),\"db2:\",len(val_sets),\"db3:\",len(test_sets))\n",
    "batch_size=2\n",
    "#pdb.set_trace()\n",
    "# 创建数据集的可迭代对象，并且分批、打乱数据集\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_sets, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_sets, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(train_loader.dataset)\n",
    "print(next(iter(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f92866",
   "metadata": {},
   "source": [
    "### Forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d75a7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyFNN_Model(nn.Module):\n",
    "    def __init__(self,num_features, num_labels):\n",
    "        super(MyFNN_Model,self).__init__()\n",
    "        self.fc1=nn.Linear(num_features,100)\n",
    "        self.fc2=nn.Linear(100,50)\n",
    "        self.fc3=nn.Linear(50,20)\n",
    "        self.fc4=nn.Linear(20,num_labels)\n",
    "        self.func=nn.Tanh()\n",
    "        \n",
    "    def forward(self,x):# batch_size, sequence, input_size=features_dim\n",
    "        y0=self.fc1(x)\n",
    "        y1=self.func(y0)\n",
    "        y2=F.dropout(y1,training=self.training)\n",
    "        \n",
    "        y3=self.fc2(y2)\n",
    "        y4=self.func(y3)\n",
    "        y5=F.dropout(y4,training=self.training)\n",
    "        \n",
    "        y6=self.fc3(y5)\n",
    "        y7=self.func(y6)\n",
    "        y8=F.dropout(y7,training=self.training)\n",
    "        \n",
    "        y9=self.fc4(y8)\n",
    "        y10=y9\n",
    "        #y10=self.func(y9)\n",
    "        #y11=F.dropout(y10,training=self.training)\n",
    "        return y10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeac6d7",
   "metadata": {},
   "source": [
    "## Training: FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66e7922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Declare super parameters\n",
    "# Two legs's knee angles, right: interal rotation, abduction, flexion as well as left size: ...\n",
    "import matplotlib.pyplot as plt\n",
    "batch_size=100\n",
    "epochs=1000\n",
    "learning_rate=0.00001\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "h5format_dataset=\"raw_datasets.hdf5\"\n",
    "\n",
    "\"\"\"\n",
    "features_names=['L_Up_Quat_q0', 'L_Up_Quat_q1', 'L_Up_Quat_q2', 'L_Up_Quat_q3',\n",
    "                        'L_Lower_Quat_q0', 'L_Lower_Quat_q1', 'L_Lower_Quat_q2', 'L_Lower_Quat_q3',\n",
    "                        'R_Up_Quat_q0', 'R_Up_Quat_q1', 'R_Up_Quat_q2', 'R_Up_Quat_q3',\n",
    "                       'R_Lower_Quat_q0', 'R_Lower_Quat_q1', 'R_Lower_Quat_q2', 'R_Lower_Quat_q3']\n",
    "\"\"\"\n",
    "##labels_names=['R_IE', 'R_AA', 'R_FE', 'L_IE', 'L_AA', 'L_FE']\n",
    "labels_names=['R_FE']\n",
    "features_names=['L_Up_Acc_X', 'L_Up_Acc_Y', 'L_Up_Acc_Z', 'L_Up_Gyr_X', 'L_Up_Gyr_Y','L_Up_Gyr_Z',\n",
    "'L_Lower_Acc_X', 'L_Lower_Acc_Y', 'L_Lower_Acc_Z', 'L_Lower_Gyr_X', 'L_Lower_Gyr_Y','L_Lower_Gyr_Z',\n",
    "'R_Up_Acc_X', 'R_Up_Acc_Y', 'R_Up_Acc_Z', 'R_Up_Gyr_X', 'R_Up_Gyr_Y','R_Up_Gyr_Z',\n",
    "'R_Lower_Acc_X', 'R_Lower_Acc_Y', 'R_Lower_Acc_Z', 'R_Lower_Gyr_X', 'R_Lower_Gyr_Y','R_Lower_Gyr_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61bb3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.5825323462486267\n",
      "epoch: 3, loss: 0.6242890954017639\n",
      "epoch: 4, loss: 0.5089030265808105\n",
      "epoch: 6, loss: 0.43830999732017517\n",
      "epoch: 8, loss: 0.3377300500869751\n",
      "epoch: 9, loss: 0.34780699014663696\n",
      "epoch: 11, loss: 0.3442181646823883\n",
      "epoch: 13, loss: 0.4449857175350189\n",
      "epoch: 14, loss: 0.2639532685279846\n",
      "epoch: 16, loss: 0.43499481678009033\n",
      "epoch: 18, loss: 0.4677141606807709\n",
      "epoch: 19, loss: 0.6307927370071411\n",
      "epoch: 21, loss: 0.40946364402770996\n",
      "epoch: 23, loss: 0.35035642981529236\n",
      "epoch: 24, loss: 0.4093080163002014\n",
      "epoch: 26, loss: 0.21593502163887024\n",
      "epoch: 28, loss: 0.38611742854118347\n",
      "epoch: 29, loss: 0.405556857585907\n",
      "epoch: 31, loss: 0.3169403672218323\n",
      "epoch: 33, loss: 0.37626802921295166\n",
      "epoch: 34, loss: 0.3568277657032013\n",
      "epoch: 36, loss: 0.39532628655433655\n",
      "epoch: 38, loss: 0.3189440667629242\n",
      "epoch: 39, loss: 0.2666265666484833\n",
      "epoch: 41, loss: 0.4887693226337433\n",
      "epoch: 43, loss: 0.7023125290870667\n",
      "epoch: 44, loss: 0.34117478132247925\n",
      "epoch: 46, loss: 0.3503268361091614\n",
      "epoch: 48, loss: 0.3853500187397003\n",
      "epoch: 49, loss: 0.17571330070495605\n",
      "epoch: 51, loss: 0.37696129083633423\n",
      "epoch: 53, loss: 0.5212201476097107\n",
      "epoch: 54, loss: 0.2693561613559723\n",
      "epoch: 56, loss: 0.1727537363767624\n",
      "epoch: 58, loss: 0.4257274568080902\n",
      "epoch: 59, loss: 0.20237025618553162\n",
      "epoch: 61, loss: 0.2613210082054138\n",
      "epoch: 63, loss: 0.34732508659362793\n",
      "epoch: 64, loss: 0.421538382768631\n",
      "epoch: 66, loss: 0.3175933361053467\n",
      "epoch: 68, loss: 0.33715400099754333\n",
      "epoch: 69, loss: 0.24032709002494812\n",
      "epoch: 71, loss: 0.2569648027420044\n",
      "epoch: 73, loss: 0.34705767035484314\n",
      "epoch: 74, loss: 0.296457976102829\n",
      "epoch: 76, loss: 0.43592125177383423\n",
      "epoch: 78, loss: 0.30556434392929077\n",
      "epoch: 79, loss: 0.4122931659221649\n",
      "epoch: 81, loss: 0.37612226605415344\n",
      "epoch: 83, loss: 0.2921561896800995\n",
      "epoch: 84, loss: 0.5382254123687744\n",
      "epoch: 86, loss: 0.40198221802711487\n",
      "epoch: 88, loss: 0.30909475684165955\n",
      "epoch: 89, loss: 0.34716087579727173\n",
      "epoch: 91, loss: 0.23684939742088318\n",
      "epoch: 93, loss: 0.254207044839859\n",
      "epoch: 94, loss: 0.35639655590057373\n",
      "epoch: 96, loss: 0.2323792427778244\n",
      "epoch: 98, loss: 0.2934209406375885\n",
      "epoch: 99, loss: 0.24587127566337585\n",
      "epoch: 101, loss: 0.22852633893489838\n",
      "epoch: 103, loss: 0.30149248242378235\n",
      "epoch: 104, loss: 0.21463555097579956\n",
      "epoch: 106, loss: 0.3669608235359192\n",
      "epoch: 108, loss: 0.24219374358654022\n",
      "epoch: 109, loss: 0.27038899064064026\n",
      "epoch: 111, loss: 0.23005425930023193\n",
      "epoch: 113, loss: 0.2387119084596634\n",
      "epoch: 114, loss: 0.38875940442085266\n",
      "epoch: 116, loss: 0.21686702966690063\n",
      "epoch: 118, loss: 0.2916197180747986\n",
      "epoch: 119, loss: 0.2376488894224167\n",
      "epoch: 121, loss: 0.44335228204727173\n",
      "epoch: 123, loss: 0.32979699969291687\n",
      "epoch: 124, loss: 0.3483189344406128\n",
      "epoch: 126, loss: 0.26715293526649475\n",
      "epoch: 128, loss: 0.22939962148666382\n",
      "epoch: 129, loss: 0.3025077283382416\n",
      "epoch: 131, loss: 0.20768512785434723\n",
      "epoch: 133, loss: 0.28757864236831665\n",
      "epoch: 134, loss: 0.3141840398311615\n",
      "epoch: 136, loss: 0.2985379099845886\n",
      "epoch: 138, loss: 0.3339442312717438\n",
      "epoch: 139, loss: 0.3174358606338501\n",
      "epoch: 141, loss: 0.29927048087120056\n",
      "epoch: 143, loss: 0.33464759588241577\n",
      "epoch: 144, loss: 0.2518579363822937\n",
      "epoch: 146, loss: 0.28376883268356323\n",
      "epoch: 148, loss: 0.42566007375717163\n",
      "epoch: 149, loss: 0.3332437574863434\n",
      "epoch: 151, loss: 0.2725554406642914\n",
      "epoch: 153, loss: 0.35487276315689087\n",
      "epoch: 154, loss: 0.4449852406978607\n",
      "epoch: 156, loss: 0.3151925802230835\n",
      "epoch: 158, loss: 0.311715304851532\n",
      "epoch: 159, loss: 0.24475747346878052\n",
      "epoch: 161, loss: 0.21100787818431854\n",
      "epoch: 163, loss: 0.3038753867149353\n",
      "epoch: 164, loss: 0.3004071116447449\n",
      "epoch: 166, loss: 0.2663283050060272\n",
      "epoch: 168, loss: 0.3009364604949951\n",
      "epoch: 169, loss: 0.30187293887138367\n",
      "epoch: 171, loss: 0.25296470522880554\n",
      "epoch: 173, loss: 0.24979029595851898\n",
      "epoch: 174, loss: 0.20668964087963104\n",
      "epoch: 176, loss: 0.26637503504753113\n",
      "epoch: 178, loss: 0.30528953671455383\n",
      "epoch: 179, loss: 0.2902485728263855\n",
      "epoch: 181, loss: 0.36857375502586365\n",
      "epoch: 183, loss: 0.3555809259414673\n",
      "epoch: 184, loss: 0.25465160608291626\n",
      "epoch: 186, loss: 0.14229223132133484\n",
      "epoch: 188, loss: 0.2055371105670929\n",
      "epoch: 189, loss: 0.3429785966873169\n",
      "epoch: 191, loss: 0.23774287104606628\n",
      "epoch: 193, loss: 0.2809940576553345\n",
      "epoch: 194, loss: 0.3097551167011261\n",
      "epoch: 196, loss: 0.24942760169506073\n",
      "epoch: 198, loss: 0.2685151696205139\n",
      "epoch: 199, loss: 0.23558834195137024\n",
      "epoch: 201, loss: 0.28991377353668213\n",
      "epoch: 203, loss: 0.2585172653198242\n",
      "epoch: 204, loss: 0.4462425112724304\n",
      "epoch: 206, loss: 0.30565786361694336\n",
      "epoch: 208, loss: 0.26629915833473206\n",
      "epoch: 209, loss: 0.2620035707950592\n",
      "epoch: 211, loss: 0.38925081491470337\n",
      "epoch: 213, loss: 0.30891498923301697\n",
      "epoch: 214, loss: 0.19619297981262207\n",
      "epoch: 216, loss: 0.23805217444896698\n",
      "epoch: 218, loss: 0.17020682990550995\n",
      "epoch: 219, loss: 0.37122026085853577\n",
      "epoch: 221, loss: 0.2189159393310547\n",
      "epoch: 223, loss: 0.23261520266532898\n",
      "epoch: 224, loss: 0.3362291157245636\n",
      "epoch: 226, loss: 0.2931428849697113\n",
      "epoch: 228, loss: 0.219593346118927\n",
      "epoch: 229, loss: 0.2369367480278015\n",
      "epoch: 231, loss: 0.23975475132465363\n",
      "epoch: 233, loss: 0.19802771508693695\n",
      "epoch: 234, loss: 0.21685409545898438\n",
      "epoch: 236, loss: 0.33672744035720825\n",
      "epoch: 238, loss: 0.29738861322402954\n",
      "epoch: 239, loss: 0.2117435336112976\n",
      "epoch: 241, loss: 0.2984054386615753\n",
      "epoch: 243, loss: 0.2492077350616455\n",
      "epoch: 244, loss: 0.27664557099342346\n",
      "epoch: 246, loss: 0.2419768124818802\n",
      "epoch: 248, loss: 0.2418588548898697\n",
      "epoch: 249, loss: 0.3016268014907837\n",
      "epoch: 251, loss: 0.3750511407852173\n",
      "epoch: 253, loss: 0.26672178506851196\n",
      "epoch: 254, loss: 0.25048235058784485\n",
      "epoch: 256, loss: 0.4015286862850189\n",
      "epoch: 258, loss: 0.2770402729511261\n",
      "epoch: 259, loss: 0.2419946938753128\n",
      "epoch: 261, loss: 0.20223528146743774\n",
      "epoch: 263, loss: 0.31645292043685913\n",
      "epoch: 264, loss: 0.22083072364330292\n",
      "epoch: 266, loss: 0.27463802695274353\n",
      "epoch: 268, loss: 0.18731601536273956\n",
      "epoch: 269, loss: 0.1779203563928604\n",
      "epoch: 271, loss: 0.23008456826210022\n",
      "epoch: 273, loss: 0.2918647825717926\n",
      "epoch: 274, loss: 0.24236620962619781\n",
      "epoch: 276, loss: 0.1898445338010788\n",
      "epoch: 278, loss: 0.35634204745292664\n",
      "epoch: 279, loss: 0.18959374725818634\n",
      "epoch: 281, loss: 0.24856345355510712\n",
      "epoch: 283, loss: 0.22783492505550385\n",
      "epoch: 284, loss: 0.2037944495677948\n",
      "epoch: 286, loss: 0.2655874490737915\n",
      "epoch: 288, loss: 0.2749924063682556\n",
      "epoch: 289, loss: 0.22066839039325714\n",
      "epoch: 291, loss: 0.21591728925704956\n",
      "epoch: 293, loss: 0.24028155207633972\n",
      "epoch: 294, loss: 0.25510355830192566\n",
      "epoch: 296, loss: 0.29722875356674194\n",
      "epoch: 298, loss: 0.23024989664554596\n",
      "epoch: 299, loss: 0.2631527781486511\n",
      "epoch: 301, loss: 0.22668372094631195\n",
      "epoch: 303, loss: 0.23961547017097473\n",
      "epoch: 304, loss: 0.28040605783462524\n",
      "epoch: 306, loss: 0.20382250845432281\n",
      "epoch: 308, loss: 0.2903227210044861\n",
      "epoch: 309, loss: 0.14656305313110352\n",
      "epoch: 311, loss: 0.2788058817386627\n",
      "epoch: 313, loss: 0.19360679388046265\n",
      "epoch: 314, loss: 0.20769868791103363\n",
      "epoch: 316, loss: 0.24502456188201904\n",
      "epoch: 318, loss: 0.24145153164863586\n",
      "epoch: 319, loss: 0.19775016605854034\n",
      "epoch: 321, loss: 0.2045891284942627\n",
      "epoch: 323, loss: 0.27101609110832214\n",
      "epoch: 324, loss: 0.321714848279953\n",
      "epoch: 326, loss: 0.3235013484954834\n",
      "epoch: 328, loss: 0.22512923181056976\n",
      "epoch: 329, loss: 0.208746999502182\n",
      "epoch: 331, loss: 0.23304499685764313\n",
      "epoch: 333, loss: 0.25429072976112366\n",
      "epoch: 334, loss: 0.17606227099895477\n",
      "epoch: 336, loss: 0.22439438104629517\n",
      "epoch: 338, loss: 0.328615665435791\n",
      "epoch: 339, loss: 0.21969522535800934\n",
      "epoch: 341, loss: 0.2560711205005646\n",
      "epoch: 343, loss: 0.28912651538848877\n",
      "epoch: 344, loss: 0.2840651273727417\n",
      "epoch: 346, loss: 0.36052843928337097\n",
      "epoch: 348, loss: 0.17069217562675476\n",
      "epoch: 349, loss: 0.2340758591890335\n",
      "epoch: 351, loss: 0.21637187898159027\n",
      "epoch: 353, loss: 0.2666049599647522\n",
      "epoch: 354, loss: 0.23779639601707458\n",
      "epoch: 356, loss: 0.2116091102361679\n",
      "epoch: 358, loss: 0.20914727449417114\n",
      "epoch: 359, loss: 0.19045951962471008\n",
      "epoch: 361, loss: 0.1962796151638031\n",
      "epoch: 363, loss: 0.3389209806919098\n",
      "epoch: 364, loss: 0.1653192937374115\n",
      "epoch: 366, loss: 0.16530479490756989\n",
      "epoch: 368, loss: 0.15649189054965973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 369, loss: 0.2622867226600647\n",
      "epoch: 371, loss: 0.1816360503435135\n",
      "epoch: 373, loss: 0.32094404101371765\n",
      "epoch: 374, loss: 0.22687159478664398\n",
      "epoch: 376, loss: 0.28223299980163574\n",
      "epoch: 378, loss: 0.22108443081378937\n",
      "epoch: 379, loss: 0.3808722496032715\n",
      "epoch: 381, loss: 0.2430439293384552\n",
      "epoch: 383, loss: 0.3658277094364166\n",
      "epoch: 384, loss: 0.19600163400173187\n",
      "epoch: 386, loss: 0.292203813791275\n",
      "epoch: 388, loss: 0.21625883877277374\n",
      "epoch: 389, loss: 0.2505204379558563\n",
      "epoch: 391, loss: 0.2870860695838928\n",
      "epoch: 393, loss: 0.24877242743968964\n",
      "epoch: 394, loss: 0.20567703247070312\n",
      "epoch: 396, loss: 0.17197296023368835\n",
      "epoch: 398, loss: 0.2575733959674835\n",
      "epoch: 399, loss: 0.22461245954036713\n",
      "epoch: 401, loss: 0.20170865952968597\n",
      "epoch: 403, loss: 0.3011949360370636\n",
      "epoch: 404, loss: 0.2657153606414795\n",
      "epoch: 406, loss: 0.18588756024837494\n",
      "epoch: 408, loss: 0.24101553857326508\n",
      "epoch: 409, loss: 0.305482417345047\n",
      "epoch: 411, loss: 0.19558067619800568\n",
      "epoch: 413, loss: 0.21248839795589447\n",
      "epoch: 414, loss: 0.184843510389328\n",
      "epoch: 416, loss: 0.20830579102039337\n",
      "epoch: 418, loss: 0.2671492397785187\n",
      "epoch: 419, loss: 0.27626246213912964\n",
      "epoch: 421, loss: 0.2483334094285965\n",
      "epoch: 423, loss: 0.28273165225982666\n",
      "epoch: 424, loss: 0.29381096363067627\n",
      "epoch: 426, loss: 0.22999078035354614\n",
      "epoch: 428, loss: 0.18753130733966827\n",
      "epoch: 429, loss: 0.21056383848190308\n",
      "epoch: 431, loss: 0.12303987145423889\n",
      "epoch: 433, loss: 0.1861041635274887\n",
      "epoch: 434, loss: 0.1845095157623291\n",
      "epoch: 436, loss: 0.1785155087709427\n",
      "epoch: 438, loss: 0.23532669246196747\n",
      "epoch: 439, loss: 0.22120918333530426\n",
      "epoch: 441, loss: 0.24906691908836365\n",
      "epoch: 443, loss: 0.19836856424808502\n",
      "epoch: 444, loss: 0.33982589840888977\n",
      "epoch: 446, loss: 0.3768674433231354\n",
      "epoch: 448, loss: 0.22641973197460175\n",
      "epoch: 449, loss: 0.2330462634563446\n",
      "epoch: 451, loss: 0.2631320059299469\n",
      "epoch: 453, loss: 0.27409836649894714\n",
      "epoch: 454, loss: 0.21914561092853546\n",
      "epoch: 456, loss: 0.13127301633358002\n",
      "epoch: 458, loss: 0.2821400463581085\n",
      "epoch: 459, loss: 0.17262305319309235\n",
      "epoch: 461, loss: 0.264015793800354\n",
      "epoch: 463, loss: 0.18558192253112793\n",
      "epoch: 464, loss: 0.3241724371910095\n",
      "epoch: 466, loss: 0.22794745862483978\n",
      "epoch: 468, loss: 0.190479576587677\n",
      "epoch: 469, loss: 0.2845110595226288\n",
      "epoch: 471, loss: 0.19273331761360168\n",
      "epoch: 473, loss: 0.2514629065990448\n",
      "epoch: 474, loss: 0.15020546317100525\n",
      "epoch: 476, loss: 0.32791152596473694\n",
      "epoch: 478, loss: 0.2921338975429535\n",
      "epoch: 479, loss: 0.22079339623451233\n",
      "epoch: 481, loss: 0.22251605987548828\n",
      "epoch: 483, loss: 0.1728905588388443\n",
      "epoch: 484, loss: 0.2585948407649994\n",
      "epoch: 486, loss: 0.26828092336654663\n",
      "epoch: 488, loss: 0.22731603682041168\n",
      "epoch: 489, loss: 0.2803618907928467\n",
      "epoch: 491, loss: 0.15723347663879395\n",
      "epoch: 493, loss: 0.17739184200763702\n",
      "epoch: 494, loss: 0.2598307430744171\n",
      "epoch: 496, loss: 0.24190886318683624\n",
      "epoch: 498, loss: 0.15962955355644226\n",
      "epoch: 499, loss: 0.13934874534606934\n",
      "epoch: 501, loss: 0.28268107771873474\n",
      "epoch: 503, loss: 0.2969861626625061\n",
      "epoch: 504, loss: 0.23976656794548035\n",
      "epoch: 506, loss: 0.29775363206863403\n",
      "epoch: 508, loss: 0.27434128522872925\n",
      "epoch: 509, loss: 0.2081083208322525\n",
      "epoch: 511, loss: 0.2471490353345871\n",
      "epoch: 513, loss: 0.21123458445072174\n",
      "epoch: 514, loss: 0.2398698627948761\n",
      "epoch: 516, loss: 0.15499091148376465\n",
      "epoch: 518, loss: 0.21043671667575836\n",
      "epoch: 519, loss: 0.39830437302589417\n",
      "epoch: 521, loss: 0.3475379943847656\n",
      "epoch: 523, loss: 0.2365187555551529\n",
      "epoch: 524, loss: 0.26370975375175476\n",
      "epoch: 526, loss: 0.23053805530071259\n",
      "epoch: 528, loss: 0.3202366828918457\n",
      "epoch: 529, loss: 0.27949661016464233\n",
      "epoch: 531, loss: 0.21603628993034363\n",
      "epoch: 533, loss: 0.2125915139913559\n",
      "epoch: 534, loss: 0.22199667990207672\n",
      "epoch: 536, loss: 0.18690674006938934\n",
      "epoch: 538, loss: 0.1789364218711853\n",
      "epoch: 539, loss: 0.23157848417758942\n",
      "epoch: 541, loss: 0.22015316784381866\n",
      "epoch: 543, loss: 0.22814178466796875\n",
      "epoch: 544, loss: 0.24840520322322845\n",
      "epoch: 546, loss: 0.23625487089157104\n",
      "epoch: 548, loss: 0.19564147293567657\n",
      "epoch: 549, loss: 0.2600521743297577\n",
      "epoch: 551, loss: 0.2506532371044159\n",
      "epoch: 553, loss: 0.19054345786571503\n",
      "epoch: 554, loss: 0.23212523758411407\n",
      "epoch: 556, loss: 0.2281353771686554\n",
      "epoch: 558, loss: 0.29470840096473694\n",
      "epoch: 559, loss: 0.20097285509109497\n",
      "epoch: 561, loss: 0.18345719575881958\n",
      "epoch: 563, loss: 0.19525347650051117\n",
      "epoch: 564, loss: 0.12548451125621796\n",
      "epoch: 566, loss: 0.277021586894989\n",
      "epoch: 568, loss: 0.20503799617290497\n",
      "epoch: 569, loss: 0.2369040995836258\n",
      "epoch: 571, loss: 0.15932177007198334\n",
      "epoch: 573, loss: 0.2559490501880646\n",
      "epoch: 574, loss: 0.22205127775669098\n",
      "epoch: 576, loss: 0.19578276574611664\n",
      "epoch: 578, loss: 0.3352155089378357\n",
      "epoch: 579, loss: 0.18964427709579468\n",
      "epoch: 581, loss: 0.16314814984798431\n",
      "epoch: 583, loss: 0.16859321296215057\n",
      "epoch: 584, loss: 0.1686876118183136\n",
      "epoch: 586, loss: 0.263873815536499\n",
      "epoch: 588, loss: 0.2893221080303192\n",
      "epoch: 589, loss: 0.19795991480350494\n",
      "epoch: 591, loss: 0.25193825364112854\n",
      "epoch: 593, loss: 0.17274577915668488\n",
      "epoch: 594, loss: 0.1695786416530609\n",
      "epoch: 596, loss: 0.2584886848926544\n",
      "epoch: 598, loss: 0.2669849395751953\n",
      "epoch: 599, loss: 0.26373523473739624\n",
      "epoch: 601, loss: 0.17940352857112885\n",
      "epoch: 603, loss: 0.2014189511537552\n",
      "epoch: 604, loss: 0.3144240081310272\n",
      "epoch: 606, loss: 0.19775046408176422\n",
      "epoch: 608, loss: 0.3028142750263214\n",
      "epoch: 609, loss: 0.1661781221628189\n",
      "epoch: 611, loss: 0.23894163966178894\n",
      "epoch: 613, loss: 0.29895251989364624\n",
      "epoch: 614, loss: 0.20614230632781982\n",
      "epoch: 616, loss: 0.23011603951454163\n",
      "epoch: 618, loss: 0.19780775904655457\n",
      "epoch: 619, loss: 0.2267090231180191\n",
      "epoch: 621, loss: 0.16822849214076996\n",
      "epoch: 623, loss: 0.2666186988353729\n",
      "epoch: 624, loss: 0.20022016763687134\n",
      "epoch: 626, loss: 0.26452258229255676\n",
      "epoch: 628, loss: 0.25861886143684387\n",
      "epoch: 629, loss: 0.2081109583377838\n",
      "epoch: 631, loss: 0.19662082195281982\n",
      "epoch: 633, loss: 0.2315499633550644\n",
      "epoch: 634, loss: 0.21412871778011322\n",
      "epoch: 636, loss: 0.20216110348701477\n",
      "epoch: 638, loss: 0.25729453563690186\n",
      "epoch: 639, loss: 0.17114636301994324\n",
      "epoch: 641, loss: 0.2502889633178711\n",
      "epoch: 643, loss: 0.23181739449501038\n",
      "epoch: 644, loss: 0.1632200926542282\n",
      "epoch: 646, loss: 0.24528968334197998\n",
      "epoch: 648, loss: 0.27554652094841003\n",
      "epoch: 649, loss: 0.2992455065250397\n",
      "epoch: 651, loss: 0.23887024819850922\n",
      "epoch: 653, loss: 0.1650811731815338\n",
      "epoch: 654, loss: 0.23486362397670746\n",
      "epoch: 656, loss: 0.21540822088718414\n",
      "epoch: 658, loss: 0.2002711296081543\n",
      "epoch: 659, loss: 0.26139548420906067\n",
      "epoch: 661, loss: 0.188099205493927\n",
      "epoch: 663, loss: 0.19912441074848175\n",
      "epoch: 664, loss: 0.2314247041940689\n",
      "epoch: 666, loss: 0.19410306215286255\n",
      "epoch: 668, loss: 0.21508227288722992\n",
      "epoch: 669, loss: 0.1775459200143814\n",
      "epoch: 671, loss: 0.20580917596817017\n",
      "epoch: 673, loss: 0.18834993243217468\n",
      "epoch: 674, loss: 0.2897491455078125\n",
      "epoch: 676, loss: 0.2008909434080124\n",
      "epoch: 678, loss: 0.24668803811073303\n",
      "epoch: 679, loss: 0.2135930210351944\n",
      "epoch: 681, loss: 0.24079708755016327\n",
      "epoch: 683, loss: 0.2954121530056\n",
      "epoch: 684, loss: 0.29393115639686584\n",
      "epoch: 686, loss: 0.16308967769145966\n",
      "epoch: 688, loss: 0.26561421155929565\n",
      "epoch: 689, loss: 0.22411857545375824\n",
      "epoch: 691, loss: 0.17146268486976624\n",
      "epoch: 693, loss: 0.24969953298568726\n",
      "epoch: 694, loss: 0.218560591340065\n",
      "epoch: 696, loss: 0.2411525696516037\n",
      "epoch: 698, loss: 0.20846667885780334\n",
      "epoch: 699, loss: 0.19469185173511505\n",
      "epoch: 701, loss: 0.29805198311805725\n",
      "epoch: 703, loss: 0.16135989129543304\n",
      "epoch: 704, loss: 0.46375709772109985\n",
      "epoch: 706, loss: 0.21167322993278503\n",
      "epoch: 708, loss: 0.20202895998954773\n",
      "epoch: 709, loss: 0.26308706402778625\n",
      "epoch: 711, loss: 0.2479473203420639\n",
      "epoch: 713, loss: 0.27525755763053894\n",
      "epoch: 714, loss: 0.20711831748485565\n",
      "epoch: 716, loss: 0.15215133130550385\n",
      "epoch: 718, loss: 0.3088061511516571\n",
      "epoch: 719, loss: 0.14435988664627075\n",
      "epoch: 721, loss: 0.20421870052814484\n",
      "epoch: 723, loss: 0.2507641613483429\n",
      "epoch: 724, loss: 0.21377317607402802\n",
      "epoch: 726, loss: 0.18226763606071472\n",
      "epoch: 728, loss: 0.20525485277175903\n",
      "epoch: 729, loss: 0.22794289886951447\n",
      "epoch: 731, loss: 0.2056179642677307\n",
      "epoch: 733, loss: 0.349264532327652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 734, loss: 0.29359933733940125\n",
      "epoch: 736, loss: 0.23883646726608276\n",
      "epoch: 738, loss: 0.22000080347061157\n",
      "epoch: 739, loss: 0.15196023881435394\n",
      "epoch: 741, loss: 0.1655951291322708\n",
      "epoch: 743, loss: 0.1434149146080017\n",
      "epoch: 744, loss: 0.18458396196365356\n",
      "epoch: 746, loss: 0.22544433176517487\n",
      "epoch: 748, loss: 0.2626582384109497\n",
      "epoch: 749, loss: 0.28369778394699097\n",
      "epoch: 751, loss: 0.2711268663406372\n",
      "epoch: 753, loss: 0.18453314900398254\n",
      "epoch: 754, loss: 0.17682017385959625\n",
      "epoch: 756, loss: 0.18766795098781586\n",
      "epoch: 758, loss: 0.15394414961338043\n",
      "epoch: 759, loss: 0.17214937508106232\n",
      "epoch: 761, loss: 0.19226695597171783\n",
      "epoch: 763, loss: 0.22768568992614746\n",
      "epoch: 764, loss: 0.17106269299983978\n",
      "epoch: 766, loss: 0.24220848083496094\n",
      "epoch: 768, loss: 0.19178493320941925\n",
      "epoch: 769, loss: 0.2208012342453003\n",
      "epoch: 771, loss: 0.14901135861873627\n",
      "epoch: 773, loss: 0.24454562366008759\n",
      "epoch: 774, loss: 0.1233142837882042\n",
      "epoch: 776, loss: 0.25416049361228943\n",
      "epoch: 778, loss: 0.2373296320438385\n",
      "epoch: 779, loss: 0.22243502736091614\n",
      "epoch: 781, loss: 0.180435448884964\n",
      "epoch: 783, loss: 0.2712811827659607\n",
      "epoch: 784, loss: 0.21724176406860352\n",
      "epoch: 786, loss: 0.2473112791776657\n",
      "epoch: 788, loss: 0.26830732822418213\n",
      "epoch: 789, loss: 0.26033422350883484\n",
      "epoch: 791, loss: 0.1814708113670349\n",
      "epoch: 793, loss: 0.19328972697257996\n",
      "epoch: 794, loss: 0.20559103786945343\n",
      "epoch: 796, loss: 0.18688039481639862\n",
      "epoch: 798, loss: 0.1723565012216568\n",
      "epoch: 799, loss: 0.17519943416118622\n",
      "epoch: 801, loss: 0.2989702820777893\n",
      "epoch: 803, loss: 0.3060118854045868\n",
      "epoch: 804, loss: 0.23786579072475433\n",
      "epoch: 806, loss: 0.2005814164876938\n",
      "epoch: 808, loss: 0.20571765303611755\n",
      "epoch: 809, loss: 0.26895737648010254\n",
      "epoch: 811, loss: 0.21297377347946167\n",
      "epoch: 813, loss: 0.24052882194519043\n",
      "epoch: 814, loss: 0.2567710876464844\n",
      "epoch: 816, loss: 0.17642398178577423\n",
      "epoch: 818, loss: 0.2946091592311859\n",
      "epoch: 819, loss: 0.29454654455184937\n",
      "epoch: 821, loss: 0.15946632623672485\n",
      "epoch: 823, loss: 0.24097418785095215\n",
      "epoch: 824, loss: 0.19376471638679504\n",
      "epoch: 826, loss: 0.17440824210643768\n",
      "epoch: 828, loss: 0.1822597086429596\n",
      "epoch: 829, loss: 0.1983713060617447\n",
      "epoch: 831, loss: 0.2685777544975281\n",
      "epoch: 833, loss: 0.22911673784255981\n",
      "epoch: 834, loss: 0.1835273951292038\n",
      "epoch: 836, loss: 0.15036973357200623\n",
      "epoch: 838, loss: 0.21039016544818878\n",
      "epoch: 839, loss: 0.3158636689186096\n",
      "epoch: 841, loss: 0.24838033318519592\n",
      "epoch: 843, loss: 0.20715369284152985\n",
      "epoch: 844, loss: 0.21864771842956543\n",
      "epoch: 846, loss: 0.1660071164369583\n",
      "epoch: 848, loss: 0.1996949166059494\n",
      "epoch: 849, loss: 0.25423020124435425\n",
      "epoch: 851, loss: 0.18977145850658417\n",
      "epoch: 853, loss: 0.24539704620838165\n",
      "epoch: 854, loss: 0.20045018196105957\n",
      "epoch: 856, loss: 0.2818091809749603\n",
      "epoch: 858, loss: 0.20561513304710388\n",
      "epoch: 859, loss: 0.29792582988739014\n",
      "epoch: 861, loss: 0.26322200894355774\n",
      "epoch: 863, loss: 0.2314612865447998\n",
      "epoch: 864, loss: 0.13735395669937134\n",
      "epoch: 866, loss: 0.23228992521762848\n",
      "epoch: 868, loss: 0.2251286804676056\n",
      "epoch: 869, loss: 0.22381377220153809\n",
      "epoch: 871, loss: 0.21877343952655792\n",
      "epoch: 873, loss: 0.20494955778121948\n",
      "epoch: 874, loss: 0.24226059019565582\n",
      "epoch: 876, loss: 0.265611469745636\n",
      "epoch: 878, loss: 0.20364435017108917\n",
      "epoch: 879, loss: 0.18168087303638458\n",
      "epoch: 881, loss: 0.1623123288154602\n",
      "epoch: 883, loss: 0.2019331306219101\n",
      "epoch: 884, loss: 0.21082772314548492\n",
      "epoch: 886, loss: 0.2172546088695526\n",
      "epoch: 888, loss: 0.3363531529903412\n",
      "epoch: 889, loss: 0.17401862144470215\n",
      "epoch: 891, loss: 0.25325149297714233\n",
      "epoch: 893, loss: 0.1868722289800644\n",
      "epoch: 894, loss: 0.16781054437160492\n",
      "epoch: 896, loss: 0.22397029399871826\n",
      "epoch: 898, loss: 0.20680110156536102\n",
      "epoch: 899, loss: 0.26884710788726807\n",
      "epoch: 901, loss: 0.23635783791542053\n",
      "epoch: 903, loss: 0.19653211534023285\n",
      "epoch: 904, loss: 0.22297969460487366\n",
      "epoch: 906, loss: 0.18776825070381165\n",
      "epoch: 908, loss: 0.21123580634593964\n",
      "epoch: 909, loss: 0.16854232549667358\n",
      "epoch: 911, loss: 0.23674170672893524\n",
      "epoch: 913, loss: 0.23448877036571503\n",
      "epoch: 914, loss: 0.17042121291160583\n",
      "epoch: 916, loss: 0.23019808530807495\n",
      "epoch: 918, loss: 0.19900597631931305\n",
      "epoch: 919, loss: 0.189517080783844\n",
      "epoch: 921, loss: 0.17803043127059937\n",
      "epoch: 923, loss: 0.29750484228134155\n",
      "epoch: 924, loss: 0.1955745667219162\n",
      "epoch: 926, loss: 0.21515364944934845\n",
      "epoch: 928, loss: 0.22379283607006073\n",
      "epoch: 929, loss: 0.16976657509803772\n",
      "epoch: 931, loss: 0.20489047467708588\n",
      "epoch: 933, loss: 0.21673764288425446\n",
      "epoch: 934, loss: 0.18840567767620087\n",
      "epoch: 936, loss: 0.15854083001613617\n",
      "epoch: 938, loss: 0.2635642886161804\n",
      "epoch: 939, loss: 0.20269034802913666\n",
      "epoch: 941, loss: 0.2081156075000763\n",
      "epoch: 943, loss: 0.18208041787147522\n",
      "epoch: 944, loss: 0.19035838544368744\n",
      "epoch: 946, loss: 0.18261878192424774\n",
      "epoch: 948, loss: 0.1634245067834854\n",
      "epoch: 949, loss: 0.28892210125923157\n",
      "epoch: 951, loss: 0.19152072072029114\n",
      "epoch: 953, loss: 0.2306913137435913\n",
      "epoch: 954, loss: 0.29541075229644775\n",
      "epoch: 956, loss: 0.21405953168869019\n",
      "epoch: 958, loss: 0.19432717561721802\n",
      "epoch: 959, loss: 0.1835828423500061\n",
      "epoch: 961, loss: 0.17509503662586212\n",
      "epoch: 963, loss: 0.2038862705230713\n",
      "epoch: 964, loss: 0.1660294234752655\n",
      "epoch: 966, loss: 0.2213154137134552\n",
      "epoch: 968, loss: 0.19119378924369812\n",
      "epoch: 969, loss: 0.1930294632911682\n",
      "epoch: 971, loss: 0.1625976860523224\n",
      "epoch: 973, loss: 0.24635601043701172\n",
      "epoch: 974, loss: 0.159236878156662\n",
      "epoch: 976, loss: 0.35545074939727783\n",
      "epoch: 978, loss: 0.2365076243877411\n",
      "epoch: 979, loss: 0.19105517864227295\n",
      "epoch: 981, loss: 0.19161975383758545\n",
      "epoch: 983, loss: 0.16397638618946075\n",
      "epoch: 984, loss: 0.25804561376571655\n",
      "epoch: 986, loss: 0.17472216486930847\n",
      "epoch: 988, loss: 0.13112398982048035\n",
      "epoch: 989, loss: 0.20340240001678467\n",
      "epoch: 991, loss: 0.1686737984418869\n",
      "epoch: 993, loss: 0.17307038605213165\n",
      "epoch: 994, loss: 0.2120271474123001\n",
      "epoch: 996, loss: 0.24483981728553772\n",
      "epoch: 998, loss: 0.17884637415409088\n",
      "epoch: 999, loss: 0.1378074735403061\n"
     ]
    }
   ],
   "source": [
    "## Declare\n",
    "import os\n",
    "\n",
    "datasets=DroplandingDataset(h5format_dataset,features_names,labels_names)\n",
    "\n",
    "train_sets, test_sets, val_sets=torch.utils.data.random_split(datasets,[60000,10000,26983])\n",
    "\n",
    "# 创建数据集的可迭代对象，并且分批、打乱数据集\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_sets, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_sets, batch_size=batch_size, shuffle=True)\n",
    "#print(\"train_loader:\", next(iter(train_loader)).shape)\n",
    "\n",
    "num_features=len(features_names)\n",
    "num_labels=len(labels_names)\n",
    "\n",
    "model=MyFNN_Model(num_features,num_labels)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "#optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "iter=0\n",
    "loss_list = [] # 保存loss\n",
    "accuracy_list = [] # 保存accuracy\n",
    "iteration_list = [] # 保存循环次数\n",
    "outputs_list=[]\n",
    "\n",
    "#plt.ion()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        model.train() # 声明训练\n",
    "        features=features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 梯度清零（否则会不断累加）\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        #print(\" features shape:{}, labels shape:{} \".format(features.shape, labels.shape))\n",
    "        outputs = model(features)\n",
    "        #print(\"outputs shape:{}, labels shape:{} \".format(outputs.shape, labels.shape))\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        # 计数器自动加1\n",
    "        iter+=1\n",
    "        if(iter%1000==0):\n",
    "            #plt.cla()\n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            iteration_list.append(iter)\n",
    "            print(\"epoch: {}, loss: {}\".format(epoch,loss.cpu().detach()))\n",
    "            #Visualization of trainning\n",
    "            #plt.cla()\n",
    "            # 无误差真值曲线\n",
    "            #plt.scatter(features.cpu().numpy()[-1,1], labels.cpu().numpy()[-1,1], c='blue', lw='3')\n",
    "            # 有误差散点\n",
    "            #plt.scatter(x_data.numpy(), y_data.numpy(), c='orange')\n",
    "            # 实时预测的曲线\n",
    "            #plt.plot(iteration_list,loss_list, c='red', lw='2')\n",
    "            #plt.text(-0.5, -65, 'Time=%d Loss=%.4f' % (i, loss.cpu().data.numpy()), fontdict={'size': 15, 'color': 'red'})\n",
    "            #plt.pause(0.01)\n",
    "            \n",
    "rename_file=\"fnn_model_parameters.pk1\"\n",
    "if(os.path.exists(rename_file)):\n",
    "    os.remove(rename_file)\n",
    "torch.save(model.state_dict(),rename_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccdd162",
   "metadata": {},
   "source": [
    "### Prediction : FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef59bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## new model and load the trained model parameters\n",
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "trained_model=MyFNN_Model(num_features,num_labels)\n",
    "model_state_dic=torch.load(\"fnn_model_parameters.pk1\")\n",
    "trained_model.load_state_dict(model_state_dic)\n",
    "\n",
    "predictions=[]\n",
    "labels=[]\n",
    "features=[]\n",
    "row_idx_start=11000\n",
    "row_idx_end=11500\n",
    "fea_data_mean,fea_data_std=normalization_parameters(row_idx_start,features_names)\n",
    "lab_data_mean,lab_data_std=normalization_parameters(row_idx_start,labels_names)\n",
    "\n",
    "for idx in range(row_idx_start,row_idx_end):\n",
    "    with torch.no_grad():\n",
    "        trained_model.eval()\n",
    "        trained_model.to(device)\n",
    "        fea_temp=read_rawdata(idx,features_names)\n",
    "        features.append(fea_temp)\n",
    "        fea_temp_norm=(fea_temp-fea_data_mean.values)/fea_data_std.values\n",
    "        #fea_temp=(read_rawdata(idx,features_names)-fea_data_mean.values)/fea_data_std.values\n",
    "        #lab_temp=(read_rawdata(idx,labels_names)-lab_data_mean.values)/lab_data_std.values\n",
    "        lab_temp=read_rawdata(idx,labels_names)\n",
    "        labels.append(lab_temp)\n",
    "        fea_temp_norm=torch.from_numpy(fea_temp_norm).unsqueeze_(dim=0).to(torch.float32).to(device)\n",
    "        pre_temp_norm=trained_model(fea_temp_norm)\n",
    "        pre_temp=pre_temp_norm.cpu().numpy()*lab_data_std.values+lab_data_std.values\n",
    "        predictions.append(pre_temp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20cd84e",
   "metadata": {},
   "source": [
    "## Prediction visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41f7b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels:\n",
      "         R_FE\n",
      "0  61.427350\n",
      "1  59.505964\n",
      "2  57.231817\n",
      "3  54.981885\n",
      "4  52.576291\n",
      "Predictions:\n",
      "         R_FE\n",
      "0  82.500565\n",
      "1  82.920938\n",
      "2  83.632837\n",
      "3  82.054024\n",
      "4  77.452883\n",
      "Error:\n",
      "         R_FE\n",
      "0  21.073215\n",
      "1  23.414973\n",
      "2  26.401020\n",
      "3  27.072139\n",
      "4  24.876592\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x792 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# features\n",
    "features=np.squeeze(np.array(features))\n",
    "# lablels\n",
    "labels=np.squeeze(np.array(labels))\n",
    "# predictions\n",
    "predictions=np.squeeze(np.array(predictions))\n",
    "\n",
    "# Pandas DataFrame of the above datasets\n",
    "pd_features=pd.DataFrame(features,columns=features_names)\n",
    "pd_labels=pd.DataFrame(labels,columns=labels_names)\n",
    "pd_predictions=pd.DataFrame(data=predictions,columns=labels_names)\n",
    "\n",
    "#figsize=(8,8)\n",
    "#fig=plt.figure(figsize=figsize)\n",
    "#sns.lineplot(data=pd_labels,x=range(pd_labels.shape[0]),y='R_IE')\n",
    "\n",
    "\n",
    "freq=100.0;\n",
    "Time=np.linspace(0,labels.shape[0]/freq,num=labels.shape[0])\n",
    "figsize=(14,11)\n",
    "fig=plt.figure(figsize=figsize)\n",
    "axs=fig.subplots(3,1)\n",
    "\"\"\"\n",
    "\n",
    "axs[0].plot(Time,pd_labels['R_IE'],\"g\")\n",
    "axs[0].plot(Time, pd_predictions['R_IE'],\"r\")\n",
    "axs[0].legend(['Actual knee','Estimated knee'])\n",
    "axs[0].set_xlabel(\"Time [s]\")\n",
    "axs[0].set_ylabel(u\"$IE [\\deg]$\")\n",
    "\n",
    "axs[1].plot(Time,pd_labels['R_AA'],\"g\")\n",
    "axs[1].plot(Time,pd_predictions['R_AA'],\"r\")\n",
    "axs[1].legend(['Actual knee','Estimated knee'])\n",
    "axs[1].set_xlabel(\"Time [s]\")\n",
    "axs[1].set_ylabel(u\"$AA [\\deg]$\")\n",
    "\"\"\"\n",
    "\n",
    "axs[2].plot(Time, pd_labels['R_FE'],\"g\")\n",
    "axs[2].plot(Time, pd_predictions['R_FE'],\"r\")\n",
    "axs[2].legend(['Actual knee','Estimated knee'])\n",
    "axs[2].set_xlabel(\"Time [s]\")\n",
    "axs[2].set_ylabel(u\"$FE [\\deg]$\")\n",
    "\n",
    "\n",
    "#ESM\n",
    "R_IE_error=pd_predictions-pd_labels\n",
    "print(\"Actual labels:\\n\",pd_labels.head())\n",
    "print(\"Predictions:\\n\",pd_predictions.head())\n",
    "print(\"Error:\\n\",R_IE_error.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df12ac",
   "metadata": {},
   "source": [
    "## LSTM V1.0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c00bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "class MyLSTM_Model(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,layer_dim,output_dim):\n",
    "        super(MyLSTM_Model,self).__init__()\n",
    "        self.input_dim=input_dim\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.layer_dim=layer_dim\n",
    "        self.output_dim=output_dim\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
    "        self.lstm=nn.LSTM(self.input_dim,self.hidden_dim,self.layer_dim,batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_dim,output_dim) #(16,6)\n",
    "        \n",
    "    def forward(self,x):# batch_size, sequence, input_size=features_dim\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0=torch.zeros(self.layer_dim,x.size(0),self.hidden_dim).to(device)\n",
    "        c0=torch.zeros(self.layer_dim,x.size(0),self.hidden_dim).to(device)\n",
    "        out,(hn,cn)=self.lstm(x,(h0.detach(),c0.detach()))\n",
    "        print(\"out shape:\",out.shape)\n",
    "        results=self.fc(out[:,-1,:])# batch size=10, sequence_dim (1),hidden_dim (16)\n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb24fc5",
   "metadata": {},
   "source": [
    "## LSTM V2.0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5740e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.2):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            dropout=dropout,\n",
    "            bidirectional=False, )\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        seq_length = x.size()[1]\n",
    "\n",
    "        x = x.view(seq_length, batch_size, -1)\n",
    "\n",
    "        # We need to pass the initial cell states\n",
    "        h0 = Variable(torch.zeros(seq_length, batch_size, self.hidden_size))\n",
    "        c0 = Variable(torch.zeros(seq_length, batch_size, self.hidden_size))\n",
    "        outputs, (ht, ct) = self.rnn(x, (h0, c0))\n",
    "\n",
    "        out = outputs[-1]  # We are only interested in the final prediction\n",
    "        out = self.bn1(self.fc1(out))\n",
    "        out = self.relu(out)\n",
    "        out = F.dropout(out, training=self.training)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255d4cc",
   "metadata": {},
   "source": [
    "## Training: LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4d0a50",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, xpu, mkldnn, opengl, opencl, ideep, hip, msnpu, mlc, xla, vulkan, meta, hpu device type at start of device string: gpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d331f15b706a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mh5format_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raw_datasets.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, xpu, mkldnn, opengl, opencl, ideep, hip, msnpu, mlc, xla, vulkan, meta, hpu device type at start of device string: gpu"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import pdb\n",
    "# Declare super parameters\n",
    "output_dim=1 # two legs's knee angles, right: interal rotation, abduction, flexion as well as left size: ...\n",
    "input_dim=8\n",
    "layer_dim=2\n",
    "hidden_dim=8\n",
    "batch_size=20\n",
    "epochs=5\n",
    "sequence_dim=1\n",
    "learning_rate=0.01\n",
    "\n",
    "device=torch.device(\"gpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "h5format_dataset=\"raw_datasets.hdf5\"\n",
    "transforms_dic={\"features\": transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.0,),(1.0,))]),\n",
    "               \"labels\": transforms.Compose([transforms.ToTensor,transforms.Normalize((0.0,),(1.0,))])}\n",
    "#datasets = DroplandingDataset(h5format_dataset,transform=transforms_dic['features'],target_transform=transforms_dic['labels'])\n",
    "datasets=DroplandingDataset(h5format_dataset)\n",
    "\n",
    "train_sets, val_sets, test_sets=torch.utils.data.random_split(datasets,[50000,10000,36983])\n",
    "#print(\"db1:\",len(train_sets),\"db2:\",len(val_sets),\"db3:\",len(test_sets))\n",
    "#print(train_sets.dataset)\n",
    "\n",
    "#pdb.set_trace()\n",
    "# 创建数据集的可迭代对象，并且分批、打乱数据集\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_sets, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_sets, batch_size=batch_size, shuffle=True)\n",
    "#print(\"train_loader:\", next(iter(train_loader)).shape)\n",
    "\n",
    "#model=MyLSTM_Model(input_dim,hidden_dim,layer_dim,output_dim)\n",
    "model=MyFNN_Model(input_dim)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "iter=0\n",
    "\n",
    "loss_list = [] # 保存loss\n",
    "accuracy_list = [] # 保存accuracy\n",
    "iteration_list = [] # 保存循环次数\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        model.train() # 声明训练\n",
    "        # 一个batch的数据转换为RNN的输入维度\n",
    "        #features = features.view(-1, sequence_dim, input_dim).requires_grad_().to(device) \n",
    "        features=features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 梯度清零（否则会不断累加）\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        #print(\" features shape:{}, labels shape:{} \".format(features.shape, labels.shape))\n",
    "        outputs = model(features)\n",
    "        #print(\"outputs shape:{}, labels shape:{} \".format(outputs.shape, labels.shape))\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        # 计数器自动加1\n",
    "        iter += 1\n",
    "        # 模型验证\n",
    "        if iter % 500 == 0:\n",
    "            model.eval() # 声明\n",
    "            # 计算验证的accuracy\n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "            # 迭代测试集，获取数据、预测\n",
    "            for features,labels in test_loader:\n",
    "                features = features.to(device) \n",
    "                # 模型预测\n",
    "                outputs = model(features)\n",
    "                # 获取预测概率最大值的下标\n",
    "                #predict = torch.max(outputs.data, 1)[1]\n",
    "                # 统计测试集的大小\n",
    "                #total += labels.size(0)\n",
    "                # 统计判断/预测正确的数量\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (outputs.gpu() == labels.gpu()).sum()\n",
    "                else:\n",
    "                    correct += (outputs == labels).sum()\n",
    "            # 计算\n",
    "            accuracy = correct / total * 100\n",
    "            # 保存accuracy, loss, iteration\n",
    "            loss_list.append(loss.data)\n",
    "            accuracy_list.append(accuracy)\n",
    "            iteration_list.append(iter)\n",
    "            # 打印信息\n",
    "            print(\"loop : {}, Loss : {}, Accuracy : {}\".format(iter, loss.item(), accuracy))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
